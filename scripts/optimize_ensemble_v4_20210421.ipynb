{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/shopee-product-matching/train_fold.csv\")\n",
    "df = df[df[\"fold\"] == 0]\n",
    "tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "df['target'] = df.label_group.map(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_id = df[\"posting_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(embeddings):\n",
    "    normed_emb = normalize(embeddings).astype(np.float16)\n",
    "    distances = np.matmul(normed_emb, normed_emb.T).T\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(df, similarity_matrix, threshold, posting_id, indices=None, pred_name=\"pred\", min_n=2, mode=\"min\"):\n",
    "    preds = []\n",
    "    for k in range(len(df)):\n",
    "        if mode == \"min\": # euclid distance etc\n",
    "            IDX = np.where(similarity_matrix[k, ] < threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "        if mode == \"max\": # cosine similarlity\n",
    "            IDX = np.where(similarity_matrix[k, ] > threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[-min_n:]\n",
    "            \n",
    "        if indices is None:\n",
    "            pred = posting_id[IDX]\n",
    "        else:\n",
    "            if len(IDX) < min_n:\n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "            idx = indices[k, IDX]\n",
    "            pred = posting_id[idx]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    df[pred_name] = preds\n",
    "    f1score, precision, recall = calc_cv(df, col_name=pred_name)\n",
    "    return f1score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv(df, col_name):\n",
    "    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    df['target'] = df.label_group.map(tmp)\n",
    "    df['f1'] = df.apply(get_f1(col_name),axis=1)\n",
    "    df[\"precision\"] = df.apply(get_precision(col_name), axis=1)\n",
    "    df[\"recall\"] = df.apply(get_recall(col_name), axis=1)\n",
    "    return df[\"f1\"].mean(), df[\"precision\"].mean(), df[\"recall\"].mean()\n",
    "\n",
    "def get_f1(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score\n",
    "\n",
    "def get_precision(col):\n",
    "    def precision_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        if len(row[col]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return n / len(row[col])\n",
    "    return precision_score\n",
    "\n",
    "def get_recall(col):\n",
    "    def recall_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return n / len(row.target)\n",
    "    return recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epochs(model_path, early_stopping_round=3):\n",
    "    file_len = len(glob.glob(f\"{model_path}/indices_epoch*.npy\"))\n",
    "    return file_len - early_stopping_round - 1 # epoch は0はじまりなのでさらに1ひく\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    \"bert_transformer\": \"../output/exp051_2/20210421183516\" # CV: 0.852\n",
    "}\n",
    "\n",
    "model_dist_dict = {}\n",
    "    \n",
    "for k, path in model_dict.items():\n",
    "    best_epochs = get_best_epochs(path)\n",
    "    \n",
    "    model_dist_dict[k] = {\n",
    "        \"distances\": np.load(f\"{path}/distances_epoch{best_epochs}.npy\"),\n",
    "        \"indices\": np.load(f\"{path}/indices_epoch{best_epochs}.npy\"),\n",
    "        \"embeddings\":  np.load(f\"{path}/embeddings_epoch{best_epochs}.npy\")\n",
    "    }\n",
    "    \n",
    "    model_dist_dict[k][\"cosine_similarity\"] = get_cosine_similarity(model_dist_dict[k][\"embeddings\"]).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_any(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x = np.unique(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 1\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_all(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts == 3\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major2(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 2\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_cv(1件→2件むりやり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_distance(model_dist_dict, mode):\n",
    "    ary = []\n",
    "    \n",
    "    for k, v in model_dist_dict.items():\n",
    "        ary.append(model_dist_dict[k][\"cosine_similarity\"])\n",
    "    \n",
    "    ary = np.array(ary)\n",
    "    \n",
    "    if mode == \"min\":\n",
    "        ary = ary.min(axis=0)\n",
    "    if mode == \"mean\":\n",
    "        ary = ary.mean(axis=0)\n",
    "    if mode == \"max\":\n",
    "        ary = ary.max(axis=0)\n",
    "\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "THRESHOLD: 0.4\n",
      "model=bert_transformer [f1] 0.8235, [precision] 0.764, [recall] 0.958\n",
      "<<<ensemble_ANY>>>: [f1] 0.8235, [precision] 0.764, [recall] 0.958\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8235, [precision] 0.764, [recall] 0.958\n",
      "<<aggregate_min>> [f1] 0.8235, [precision] 0.764, [recall] 0.958\n",
      "<<aggregate_max>> [f1] 0.8235, [precision] 0.764, [recall] 0.958\n",
      "=========================================================\n",
      "THRESHOLD: 0.41000000000000003\n",
      "model=bert_transformer [f1] 0.8378, [precision] 0.7866, [recall] 0.9551\n",
      "<<<ensemble_ANY>>>: [f1] 0.8378, [precision] 0.7866, [recall] 0.9551\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8378, [precision] 0.7866, [recall] 0.9551\n",
      "<<aggregate_min>> [f1] 0.8378, [precision] 0.7866, [recall] 0.9551\n",
      "<<aggregate_max>> [f1] 0.8378, [precision] 0.7866, [recall] 0.9551\n",
      "=========================================================\n",
      "THRESHOLD: 0.42000000000000004\n",
      "model=bert_transformer [f1] 0.8499, [precision] 0.8068, [recall] 0.9519\n",
      "<<<ensemble_ANY>>>: [f1] 0.8499, [precision] 0.8068, [recall] 0.9519\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8499, [precision] 0.8068, [recall] 0.9519\n",
      "<<aggregate_min>> [f1] 0.8499, [precision] 0.8068, [recall] 0.9519\n",
      "<<aggregate_max>> [f1] 0.8499, [precision] 0.8068, [recall] 0.9519\n",
      "=========================================================\n",
      "THRESHOLD: 0.43000000000000005\n",
      "model=bert_transformer [f1] 0.8604, [precision] 0.8253, [recall] 0.9487\n",
      "<<<ensemble_ANY>>>: [f1] 0.8604, [precision] 0.8253, [recall] 0.9487\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8604, [precision] 0.8253, [recall] 0.9487\n",
      "<<aggregate_min>> [f1] 0.8604, [precision] 0.8253, [recall] 0.9487\n",
      "<<aggregate_max>> [f1] 0.8604, [precision] 0.8253, [recall] 0.9487\n",
      "=========================================================\n",
      "THRESHOLD: 0.44000000000000006\n",
      "model=bert_transformer [f1] 0.8693, [precision] 0.8417, [recall] 0.9453\n",
      "<<<ensemble_ANY>>>: [f1] 0.8693, [precision] 0.8417, [recall] 0.9453\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8693, [precision] 0.8417, [recall] 0.9453\n",
      "<<aggregate_min>> [f1] 0.8693, [precision] 0.8417, [recall] 0.9453\n",
      "<<aggregate_max>> [f1] 0.8693, [precision] 0.8417, [recall] 0.9453\n",
      "=========================================================\n",
      "THRESHOLD: 0.45000000000000007\n",
      "model=bert_transformer [f1] 0.8765, [precision] 0.8555, [recall] 0.9423\n",
      "<<<ensemble_ANY>>>: [f1] 0.8765, [precision] 0.8555, [recall] 0.9423\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8765, [precision] 0.8555, [recall] 0.9423\n",
      "<<aggregate_min>> [f1] 0.8765, [precision] 0.8555, [recall] 0.9423\n",
      "<<aggregate_max>> [f1] 0.8765, [precision] 0.8555, [recall] 0.9423\n",
      "=========================================================\n",
      "THRESHOLD: 0.4600000000000001\n",
      "model=bert_transformer [f1] 0.8828, [precision] 0.8687, [recall] 0.9384\n",
      "<<<ensemble_ANY>>>: [f1] 0.8828, [precision] 0.8687, [recall] 0.9384\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8828, [precision] 0.8687, [recall] 0.9384\n",
      "<<aggregate_min>> [f1] 0.8828, [precision] 0.8687, [recall] 0.9384\n",
      "<<aggregate_max>> [f1] 0.8828, [precision] 0.8687, [recall] 0.9384\n",
      "=========================================================\n",
      "THRESHOLD: 0.4700000000000001\n",
      "model=bert_transformer [f1] 0.8886, [precision] 0.8804, [recall] 0.9355\n",
      "<<<ensemble_ANY>>>: [f1] 0.8886, [precision] 0.8804, [recall] 0.9355\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8886, [precision] 0.8804, [recall] 0.9355\n",
      "<<aggregate_min>> [f1] 0.8886, [precision] 0.8804, [recall] 0.9355\n",
      "<<aggregate_max>> [f1] 0.8886, [precision] 0.8804, [recall] 0.9355\n",
      "=========================================================\n",
      "THRESHOLD: 0.4800000000000001\n",
      "model=bert_transformer [f1] 0.8922, [precision] 0.8903, [recall] 0.9307\n",
      "<<<ensemble_ANY>>>: [f1] 0.8922, [precision] 0.8903, [recall] 0.9307\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8922, [precision] 0.8903, [recall] 0.9307\n",
      "<<aggregate_min>> [f1] 0.8922, [precision] 0.8903, [recall] 0.9307\n",
      "<<aggregate_max>> [f1] 0.8922, [precision] 0.8903, [recall] 0.9307\n",
      "=========================================================\n",
      "THRESHOLD: 0.4900000000000001\n",
      "model=bert_transformer [f1] 0.8956, [precision] 0.8996, [recall] 0.9263\n",
      "<<<ensemble_ANY>>>: [f1] 0.8956, [precision] 0.8996, [recall] 0.9263\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8956, [precision] 0.8996, [recall] 0.9263\n",
      "<<aggregate_min>> [f1] 0.8956, [precision] 0.8996, [recall] 0.9263\n",
      "<<aggregate_max>> [f1] 0.8956, [precision] 0.8996, [recall] 0.9263\n",
      "=========================================================\n",
      "THRESHOLD: 0.5000000000000001\n",
      "model=bert_transformer [f1] 0.898, [precision] 0.9081, [recall] 0.9221\n",
      "<<<ensemble_ANY>>>: [f1] 0.898, [precision] 0.9081, [recall] 0.9221\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.898, [precision] 0.9081, [recall] 0.9221\n",
      "<<aggregate_min>> [f1] 0.898, [precision] 0.9081, [recall] 0.9221\n",
      "<<aggregate_max>> [f1] 0.898, [precision] 0.9081, [recall] 0.9221\n",
      "=========================================================\n",
      "THRESHOLD: 0.5100000000000001\n",
      "model=bert_transformer [f1] 0.8996, [precision] 0.9152, [recall] 0.9177\n",
      "<<<ensemble_ANY>>>: [f1] 0.8996, [precision] 0.9152, [recall] 0.9177\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8996, [precision] 0.9152, [recall] 0.9177\n",
      "<<aggregate_min>> [f1] 0.8996, [precision] 0.9152, [recall] 0.9177\n",
      "<<aggregate_max>> [f1] 0.8996, [precision] 0.9152, [recall] 0.9177\n",
      "=========================================================\n",
      "THRESHOLD: 0.5200000000000001\n",
      "model=bert_transformer [f1] 0.9005, [precision] 0.9226, [recall] 0.9121\n",
      "<<<ensemble_ANY>>>: [f1] 0.9005, [precision] 0.9226, [recall] 0.9121\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.9005, [precision] 0.9226, [recall] 0.9121\n",
      "<<aggregate_min>> [f1] 0.9005, [precision] 0.9226, [recall] 0.9121\n",
      "<<aggregate_max>> [f1] 0.9005, [precision] 0.9226, [recall] 0.9121\n",
      "=========================================================\n",
      "THRESHOLD: 0.5300000000000001\n",
      "model=bert_transformer [f1] 0.9006, [precision] 0.9278, [recall] 0.9075\n",
      "<<<ensemble_ANY>>>: [f1] 0.9006, [precision] 0.9278, [recall] 0.9075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.9006, [precision] 0.9278, [recall] 0.9075\n",
      "<<aggregate_min>> [f1] 0.9006, [precision] 0.9278, [recall] 0.9075\n",
      "<<aggregate_max>> [f1] 0.9006, [precision] 0.9278, [recall] 0.9075\n",
      "=========================================================\n",
      "THRESHOLD: 0.5400000000000001\n",
      "model=bert_transformer [f1] 0.9001, [precision] 0.9324, [recall] 0.9022\n",
      "<<<ensemble_ANY>>>: [f1] 0.9001, [precision] 0.9324, [recall] 0.9022\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.9001, [precision] 0.9324, [recall] 0.9022\n",
      "<<aggregate_min>> [f1] 0.9001, [precision] 0.9324, [recall] 0.9022\n",
      "<<aggregate_max>> [f1] 0.9001, [precision] 0.9324, [recall] 0.9022\n",
      "=========================================================\n",
      "THRESHOLD: 0.5500000000000002\n",
      "model=bert_transformer [f1] 0.8999, [precision] 0.9373, [recall] 0.8979\n",
      "<<<ensemble_ANY>>>: [f1] 0.8999, [precision] 0.9373, [recall] 0.8979\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<<ensemble_ALL>>>: [f1] 0.0, [precision] 0.0, [recall] 0.0\n",
      "<<aggregate_mean>> [f1] 0.8999, [precision] 0.9373, [recall] 0.8979\n",
      "<<aggregate_min>> [f1] 0.8999, [precision] 0.9373, [recall] 0.8979\n",
      "<<aggregate_max>> [f1] 0.8999, [precision] 0.9373, [recall] 0.8979\n"
     ]
    }
   ],
   "source": [
    "df_result = []\n",
    "for th in np.arange(0.4, 0.55, 0.01):\n",
    "    print(\"=========================================================\")\n",
    "    print(f\"THRESHOLD: {th}\")\n",
    "    for model_name in model_dict.keys():\n",
    "        f1score, precision, recall = get_cv(df, \n",
    "                                            model_dist_dict[model_name][\"cosine_similarity\"],\n",
    "                                            th,\n",
    "                                            posting_id,\n",
    "                                            pred_name=model_name,\n",
    "                                            min_n=2,\n",
    "                                            mode=\"max\")\n",
    "        print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "    df[\"pred\"] = df.apply(combine_predictions_any, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ANY>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_major, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_major2, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_all, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ALL>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    for mode in [\"mean\", \"min\", \"max\"]:\n",
    "        f1score, precision, recall = get_cv(df,\n",
    "                                            aggregate_distance(model_dist_dict, mode=mode),\n",
    "                                            th,\n",
    "                                            posting_id,\n",
    "                                            pred_name=model_name,\n",
    "                                            min_n=2,\n",
    "                                            mode=\"max\")\n",
    "        print(f\"<<aggregate_{mode}>> [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_th(indices):\n",
    "    best_th = 0\n",
    "    best_score = 0\n",
    "    for th in np.arange(0.3, 0.7, 0.01):\n",
    "        # print(\"=========================================================\")\n",
    "        # print(f\"THRESHOLD: {th}\")\n",
    "        for model_name in model_dict.keys():\n",
    "            f1score, precision, recall = get_cv(df.iloc[indices], \n",
    "                                                model_dist_dict[model_name][\"cosine_similarity\"][indices][:, indices],\n",
    "                                                th,\n",
    "                                                posting_id[indices],\n",
    "                                                pred_name=model_name,\n",
    "                                                min_n=2,\n",
    "                                                mode=\"max\")\n",
    "            # print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "            \n",
    "            if f1score > best_score:\n",
    "                best_th = th\n",
    "                best_score = f1score\n",
    "                \n",
    "    return best_th, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-d41661d81885>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[pred_name] = preds\n",
      "<ipython-input-6-9a809ac98473>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['target'] = df.label_group.map(tmp)\n",
      "<ipython-input-6-9a809ac98473>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['f1'] = df.apply(get_f1(col_name),axis=1)\n",
      "<ipython-input-6-9a809ac98473>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"precision\"] = df.apply(get_precision(col_name), axis=1)\n",
      "<ipython-input-6-9a809ac98473>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"recall\"] = df.apply(get_recall(col_name), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, 0.34, 0.9710860225895694\n",
      "200, 0.39000000000000007, 0.9745708164041281\n",
      "300, 0.4500000000000001, 0.9608532888539646\n",
      "400, 0.4200000000000001, 0.953178882598219\n",
      "500, 0.4400000000000001, 0.9519072539103756\n",
      "600, 0.46000000000000013, 0.9430776749499259\n",
      "700, 0.47000000000000014, 0.9417523019754462\n",
      "800, 0.47000000000000014, 0.9420918701430987\n",
      "900, 0.4500000000000001, 0.9317459645708626\n",
      "1000, 0.46000000000000013, 0.9321228553481998\n",
      "1100, 0.49000000000000016, 0.9385811054294083\n",
      "1200, 0.47000000000000014, 0.9296159748148392\n",
      "1300, 0.5000000000000002, 0.9210124188055798\n",
      "1400, 0.48000000000000015, 0.9234897309864691\n",
      "1500, 0.47000000000000014, 0.932424284991414\n",
      "1600, 0.49000000000000016, 0.9182132181958329\n",
      "1700, 0.49000000000000016, 0.9184718348640937\n",
      "1800, 0.49000000000000016, 0.9172969941889205\n",
      "1900, 0.5000000000000002, 0.9187837742355389\n",
      "2000, 0.5000000000000002, 0.9167583047386818\n",
      "2100, 0.5200000000000002, 0.9179131037879888\n",
      "2200, 0.5000000000000002, 0.9270324292196197\n",
      "2300, 0.5000000000000002, 0.9233548288496718\n",
      "2400, 0.5100000000000002, 0.9108596361593916\n",
      "2500, 0.49000000000000016, 0.9133548036487565\n",
      "2600, 0.5200000000000002, 0.9130028766456141\n",
      "2700, 0.5000000000000002, 0.9139661076370126\n",
      "2800, 0.5200000000000002, 0.9089979367313514\n",
      "2900, 0.5200000000000002, 0.9177973170919576\n",
      "3000, 0.5300000000000002, 0.9101535929343079\n",
      "3100, 0.5200000000000002, 0.9085655283118543\n",
      "3200, 0.5200000000000002, 0.9051620807197147\n",
      "3300, 0.5200000000000002, 0.9092607384796906\n",
      "3400, 0.5200000000000002, 0.9051507215925653\n",
      "3500, 0.5200000000000002, 0.9076555037594985\n",
      "3600, 0.5200000000000002, 0.9086038011290308\n",
      "3700, 0.5200000000000002, 0.9064773200869432\n",
      "3800, 0.5200000000000002, 0.9076778654616434\n",
      "3900, 0.5300000000000002, 0.9083864433839497\n",
      "4000, 0.5200000000000002, 0.9082531725082498\n",
      "4100, 0.5200000000000002, 0.9052512179836667\n",
      "4200, 0.5200000000000002, 0.9046020621172602\n",
      "4300, 0.5200000000000002, 0.9061949738083479\n",
      "4400, 0.5300000000000002, 0.9074900554846091\n",
      "4500, 0.5300000000000002, 0.9059149047416465\n",
      "4600, 0.5200000000000002, 0.9045254712358889\n",
      "4700, 0.5200000000000002, 0.9054722884671995\n",
      "4800, 0.5200000000000002, 0.9020503708428351\n",
      "4900, 0.5200000000000002, 0.9061847802697302\n",
      "5000, 0.5200000000000002, 0.9025542418420816\n",
      "5100, 0.5300000000000002, 0.9042107115664725\n",
      "5200, 0.5300000000000002, 0.9034542721811054\n",
      "5300, 0.5300000000000002, 0.9044003259913769\n",
      "5400, 0.5300000000000002, 0.904641482995629\n",
      "5500, 0.5200000000000002, 0.9036067006380639\n",
      "5600, 0.5200000000000002, 0.901863175322812\n",
      "5700, 0.5200000000000002, 0.9044353728888601\n",
      "5800, 0.5200000000000002, 0.9020698743184691\n",
      "5900, 0.5200000000000002, 0.9024678411982417\n",
      "6000, 0.5200000000000002, 0.9028912245065681\n",
      "6100, 0.5200000000000002, 0.9015646363532894\n",
      "6200, 0.5200000000000002, 0.9039232281609507\n",
      "6300, 0.5300000000000002, 0.903470208315658\n",
      "6400, 0.5300000000000002, 0.9030886976874537\n",
      "6500, 0.5300000000000002, 0.9036487799766589\n",
      "6600, 0.5200000000000002, 0.9011338206247402\n",
      "6700, 0.5200000000000002, 0.9013597006455029\n",
      "6800, 0.5300000000000002, 0.9018899887385988\n",
      "6900, 0.5300000000000002, 0.9010362224721321\n",
      "7000, 0.5200000000000002, 0.9029775995572813\n",
      "7100, 0.5200000000000002, 0.904341199236788\n",
      "7200, 0.5200000000000002, 0.901799664334099\n",
      "7300, 0.5200000000000002, 0.90150234350868\n",
      "7400, 0.5300000000000002, 0.9013205086409699\n",
      "7500, 0.5300000000000002, 0.901804510397252\n",
      "7600, 0.5300000000000002, 0.9019231833419311\n",
      "7700, 0.5300000000000002, 0.9019204436339724\n",
      "7800, 0.5200000000000002, 0.9014533768328672\n",
      "7900, 0.5200000000000002, 0.9021524097593046\n",
      "8000, 0.5300000000000002, 0.9014237672569295\n",
      "8100, 0.5300000000000002, 0.901349202375463\n",
      "8200, 0.5200000000000002, 0.9017727611516858\n",
      "8300, 0.5300000000000002, 0.9010712978449291\n",
      "8400, 0.5300000000000002, 0.90183987827055\n",
      "8500, 0.5300000000000002, 0.900268492560718\n",
      "8600, 0.5300000000000002, 0.9004103186319223\n",
      "8700, 0.5300000000000002, 0.9011355950522711\n",
      "8800, 0.5200000000000002, 0.9005747172868761\n",
      "8900, 0.5200000000000002, 0.900441263938753\n",
      "9000, 0.5300000000000002, 0.9005257565647505\n",
      "9100, 0.5200000000000002, 0.9030062997761282\n",
      "9200, 0.5300000000000002, 0.9008496185919425\n",
      "9300, 0.5300000000000002, 0.901954562394104\n",
      "9400, 0.5200000000000002, 0.9009991380800374\n",
      "9500, 0.5300000000000002, 0.901146871662195\n",
      "9600, 0.5300000000000002, 0.9009929688963858\n",
      "9700, 0.5300000000000002, 0.9004833953947191\n",
      "9800, 0.5200000000000002, 0.8998604305470105\n",
      "9900, 0.5300000000000002, 0.9013084545919446\n",
      "10000, 0.5300000000000002, 0.9002201689815148\n",
      "10100, 0.5300000000000002, 0.9012261958619661\n",
      "10200, 0.5300000000000002, 0.9018846743880691\n",
      "10300, 0.5300000000000002, 0.9007247264205838\n",
      "10400, 0.5300000000000002, 0.9007937988861516\n",
      "10500, 0.5300000000000002, 0.9011134600405593\n",
      "10600, 0.5300000000000002, 0.9015623609102117\n",
      "10700, 0.5300000000000002, 0.9004319432910923\n",
      "10800, 0.5300000000000002, 0.9010665027551179\n",
      "10900, 0.5300000000000002, 0.9004540069969938\n",
      "11000, 0.5300000000000002, 0.9007496503423779\n",
      "11100, 0.5300000000000002, 0.901893460213771\n",
      "11200, 0.5300000000000002, 0.9005287144239977\n",
      "11300, 0.5300000000000002, 0.9013334270782911\n",
      "11400, 0.5300000000000002, 0.9013778982738143\n",
      "11500, 0.5300000000000002, 0.9008342113404628\n",
      "11600, 0.5300000000000002, 0.900665831986849\n",
      "11700, 0.5300000000000002, 0.9007030247685497\n",
      "11800, 0.5300000000000002, 0.900645175296597\n",
      "11900, 0.5300000000000002, 0.9006824403710381\n",
      "12000, 0.5300000000000002, 0.9009678499961483\n",
      "12100, 0.5300000000000002, 0.9008677681001014\n",
      "12200, 0.5300000000000002, 0.9008543483623653\n",
      "12300, 0.5300000000000002, 0.9007747350316886\n",
      "12400, 0.5300000000000002, 0.9007169972969938\n",
      "12500, 0.5300000000000002, 0.900625955085413\n",
      "12600, 0.5300000000000002, 0.9006640803926007\n",
      "12700, 0.5300000000000002, 0.90058401117956\n",
      "12800, 0.5300000000000002, 0.9012820159116861\n",
      "12900, 0.5300000000000002, 0.9005851644238755\n",
      "13000, 0.5300000000000002, 0.9006321170439073\n",
      "13100, 0.5300000000000002, 0.9007326611117467\n",
      "13200, 0.5300000000000002, 0.9008686961491541\n",
      "13300, 0.5300000000000002, 0.9005755066959167\n",
      "13400, 0.5300000000000002, 0.9012706030685445\n",
      "13500, 0.5300000000000002, 0.9006782334592145\n",
      "13600, 0.5300000000000002, 0.9005642391063339\n",
      "13700, 0.5300000000000002, 0.9005820333630143\n",
      "13800, 0.5300000000000002, 0.900575928065587\n",
      "13900, 0.5300000000000002, 0.9014706033186316\n",
      "14000, 0.5300000000000002, 0.90054640116509\n",
      "14100, 0.5300000000000002, 0.9007299072071894\n",
      "14200, 0.5300000000000002, 0.9006341303614656\n",
      "14300, 0.5300000000000002, 0.900692771188509\n",
      "14400, 0.5300000000000002, 0.9008382445143661\n",
      "14500, 0.5300000000000002, 0.9006481960461903\n",
      "14600, 0.5300000000000002, 0.9008436367866732\n",
      "14700, 0.5300000000000002, 0.9005609560602802\n",
      "14800, 0.5300000000000002, 0.9006481960461903\n",
      "14900, 0.5300000000000002, 0.9006633030084714\n",
      "15000, 0.5300000000000002, 0.9005609560602803\n",
      "15100, 0.5300000000000002, 0.9007177136810879\n",
      "15200, 0.5300000000000002, 0.9004881389513613\n",
      "15300, 0.5300000000000002, 0.9005318420084752\n",
      "15400, 0.5300000000000002, 0.9005609560602802\n",
      "15500, 0.5300000000000002, 0.9006045951960057\n",
      "15600, 0.5300000000000002, 0.9006481960461903\n",
      "15700, 0.5300000000000002, 0.9007347504680957\n",
      "15800, 0.5300000000000002, 0.9005392405212145\n",
      "15900, 0.5300000000000002, 0.9006343160239927\n",
      "16000, 0.5300000000000002, 0.900619133064194\n",
      "16100, 0.5300000000000002, 0.9006481960461903\n",
      "16200, 0.5300000000000002, 0.9005609560602802\n",
      "16300, 0.5300000000000002, 0.900619133064194\n",
      "16400, 0.5300000000000002, 0.900619133064194\n",
      "16500, 0.5300000000000002, 0.900826305293872\n",
      "16600, 0.5300000000000002, 0.9005955398496232\n",
      "16700, 0.5300000000000002, 0.9006193142296847\n",
      "16800, 0.5300000000000002, 0.9006481960461903\n",
      "16900, 0.5300000000000002, 0.9006481960461903\n",
      "17000, 0.5300000000000002, 0.900617015216178\n",
      "17100, 0.5300000000000002, 0.9006481960461903\n",
      "17200, 0.5300000000000002, 0.9006481960461903\n",
      "17300, 0.5300000000000002, 0.9006481960461903\n",
      "17400, 0.5300000000000002, 0.900619133064194\n",
      "17500, 0.5300000000000002, 0.9006481960461903\n",
      "17600, 0.5300000000000002, 0.9006741845188687\n",
      "17700, 0.5300000000000002, 0.9006481960461903\n",
      "17800, 0.5300000000000002, 0.9006678873911407\n",
      "17900, 0.5300000000000002, 0.9006481960461903\n",
      "18000, 0.5300000000000002, 0.9006481960461903\n",
      "18100, 0.5300000000000002, 0.900874530730737\n",
      "18200, 0.5300000000000002, 0.9006045951960057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18300, 0.5300000000000002, 0.9006340375709532\n",
      "18400, 0.5300000000000002, 0.9006446056456128\n",
      "18500, 0.5300000000000002, 0.900619133064194\n",
      "18600, 0.5300000000000002, 0.9006481960461903\n",
      "18700, 0.5300000000000002, 0.900619133064194\n",
      "18800, 0.5300000000000002, 0.9006481960461903\n",
      "18900, 0.5300000000000002, 0.9006481960461903\n",
      "19000, 0.5300000000000002, 0.9006481960461903\n",
      "19100, 0.5300000000000002, 0.9006481960461903\n",
      "19200, 0.5300000000000002, 0.9006489551690666\n",
      "19300, 0.5300000000000002, 0.9006481960461903\n",
      "19400, 0.5300000000000002, 0.900630985917308\n",
      "19500, 0.5300000000000002, 0.9006481960461903\n",
      "19600, 0.5300000000000002, 0.900619133064194\n",
      "19700, 0.5300000000000002, 0.9007263925834764\n",
      "19800, 0.5300000000000002, 0.9006481960461903\n",
      "19900, 0.5300000000000002, 0.9006481960461903\n",
      "20000, 0.5300000000000002, 0.9005755066959168\n",
      "20100, 0.5300000000000002, 0.900619133064194\n",
      "20200, 0.5300000000000002, 0.9006481960461903\n",
      "20300, 0.5300000000000002, 0.9006481960461903\n",
      "20400, 0.5300000000000002, 0.9006481960461903\n",
      "20500, 0.5300000000000002, 0.9006481960461903\n",
      "20600, 0.5300000000000002, 0.9006481960461903\n",
      "20700, 0.5300000000000002, 0.9006481960461903\n",
      "20800, 0.5300000000000002, 0.9006481960461903\n",
      "20900, 0.5300000000000002, 0.900619133064194\n",
      "21000, 0.5300000000000002, 0.9006481960461903\n",
      "21100, 0.5300000000000002, 0.9006481960461903\n",
      "21200, 0.5300000000000002, 0.9006481960461903\n",
      "21300, 0.5300000000000002, 0.9006481960461903\n",
      "21400, 0.5300000000000002, 0.9006481960461903\n",
      "21500, 0.5300000000000002, 0.9006481960461903\n",
      "21600, 0.5300000000000002, 0.9006481960461903\n",
      "21700, 0.5300000000000002, 0.9006481960461903\n",
      "21800, 0.5300000000000002, 0.9006481960461903\n",
      "21900, 0.5300000000000002, 0.9006481960461903\n"
     ]
    }
   ],
   "source": [
    "rets = []\n",
    "for n_data in np.arange(100, 22000, 100):\n",
    "    for i in range(1):\n",
    "        label_group = np.random.choice(df[\"label_group\"].drop_duplicates().values, n_data, replace=True)\n",
    "        indices = df[df[\"label_group\"].isin(label_group)].index.values\n",
    "        best_th, best_score = calc_th(indices)\n",
    "        print(f\"{n_data}, {best_th}, {best_score}\")\n",
    "        \n",
    "        ret = {\"n_label\": n_data, \"n_data\": len(indices), \"best_th\": best_th, \"best_score\": best_score}\n",
    "        rets.append(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret = pd.DataFrame(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret.to_csv(\"ensemble_test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'best_threshold')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(df_ret[\"n_data\"].values,\n",
    "            df_ret[\"best_th\"].values, \n",
    "            alpha=0.2,\n",
    "            color=\"gray\")\n",
    "plt.xlabel(\"n_data\")\n",
    "plt.ylabel(\"best_threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
