{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/shopee-product-matching/train_fold.csv\")\n",
    "df = df[df[\"fold\"] == 0]\n",
    "tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "df['target'] = df.label_group.map(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_id = df[\"posting_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(embeddings):\n",
    "    normed_emb = normalize(embeddings).astype(np.float16)\n",
    "    distances = np.matmul(normed_emb, normed_emb.T).T\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(df, similarity_matrix, threshold, posting_id, indices=None, pred_name=\"pred\", min_n=2, mode=\"min\"):\n",
    "    preds = []\n",
    "    for k in range(len(df)):\n",
    "        if mode == \"min\": # euclid distance etc\n",
    "            IDX = np.where(similarity_matrix[k, ] < threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "        if mode == \"max\": # cosine similarlity\n",
    "            IDX = np.where(similarity_matrix[k, ] > threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[-min_n:]\n",
    "            \n",
    "        if indices is None:\n",
    "            pred = posting_id[IDX]\n",
    "        else:\n",
    "            if len(IDX) < min_n:\n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "            idx = indices[k, IDX]\n",
    "            pred = posting_id[idx]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    df[pred_name] = preds\n",
    "    f1score, precision, recall = calc_cv(df, col_name=pred_name)\n",
    "    return f1score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv(df, col_name):\n",
    "    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    df['target'] = df.label_group.map(tmp)\n",
    "    df['f1'] = df.apply(get_f1(col_name),axis=1)\n",
    "    df[\"precision\"] = df.apply(get_precision(col_name), axis=1)\n",
    "    df[\"recall\"] = df.apply(get_recall(col_name), axis=1)\n",
    "    return df[\"f1\"].mean(), df[\"precision\"].mean(), df[\"recall\"].mean()\n",
    "\n",
    "def get_f1(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score\n",
    "\n",
    "def get_precision(col):\n",
    "    def precision_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        if len(row[col]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return n / len(row[col])\n",
    "    return precision_score\n",
    "\n",
    "def get_recall(col):\n",
    "    def recall_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return n / len(row.target)\n",
    "    return recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epochs(model_path, early_stopping_round=3):\n",
    "    file_len = len(glob.glob(f\"{model_path}/indices_epoch*.npy\"))\n",
    "    return file_len - early_stopping_round - 1 # epoch は0はじまりなのでさらに1ひく\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    \"bert_indonesian\": \"../output/exp033/20210418043810\", # CV: 0.847\n",
    "    \"distilbert_base\": \"../output/exp033/20210418023429\", # CV: 0.852\n",
    "    \"bert_base\": \"../output/exp033/20210417225343\" # CV: 0.852\n",
    "}\n",
    "\n",
    "model_dist_dict = {}\n",
    "    \n",
    "for k, path in model_dict.items():\n",
    "    best_epochs = get_best_epochs(path)\n",
    "    \n",
    "    model_dist_dict[k] = {\n",
    "        \"distances\": np.load(f\"{path}/distances_epoch{best_epochs}.npy\"),\n",
    "        \"indices\": np.load(f\"{path}/indices_epoch{best_epochs}.npy\"),\n",
    "        \"embeddings\":  np.load(f\"{path}/embeddings_epoch{best_epochs}.npy\")\n",
    "    }\n",
    "    \n",
    "    model_dist_dict[k][\"cosine_similarity\"] = get_cosine_similarity(model_dist_dict[k][\"embeddings\"]).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_any(row):\n",
    "    x = np.concatenate([row['bert_indonesian'], row['distilbert_base'], row[\"bert_base\"]])\n",
    "    x = np.unique(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major(row):\n",
    "    x = np.concatenate([row['bert_indonesian'], row['distilbert_base'], row[\"bert_base\"]])\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 1\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_all(row):\n",
    "    x = np.concatenate([row['bert_indonesian'], row['distilbert_base'], row[\"bert_base\"]])\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts == 3\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major2(row):\n",
    "    x = np.concatenate([row['bert_indonesian'], row['distilbert_base'], row[\"bert_base\"]])\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 2\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_cv(1件→2件むりやり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_distance(model_dist_dict, mode):\n",
    "    ary = []\n",
    "    \n",
    "    for k, v in model_dist_dict.items():\n",
    "        ary.append(model_dist_dict[k][\"cosine_similarity\"])\n",
    "    \n",
    "    ary = np.array(ary)\n",
    "    \n",
    "    if mode == \"min\":\n",
    "        ary = ary.min(axis=0)\n",
    "    if mode == \"mean\":\n",
    "        ary = ary.mean(axis=0)\n",
    "    if mode == \"max\":\n",
    "        ary = ary.max(axis=0)\n",
    "\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "THRESHOLD: 0.4\n",
      "model=bert_indonesian [f1] 0.8392, [precision] 0.8051, [recall] 0.9428\n",
      "model=distilbert_base [f1] 0.8451, [precision] 0.8127, [recall] 0.944\n",
      "model=bert_base [f1] 0.8375, [precision] 0.7968, [recall] 0.9495\n",
      "<<<ensemble_ANY>>>: [f1] 0.7954, [precision] 0.7275, [recall] 0.9663\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8592, [precision] 0.834, [recall] 0.9481\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8759, [precision] 0.8857, [recall] 0.9219\n",
      "<<<ensemble_ALL>>>: [f1] 0.8759, [precision] 0.8857, [recall] 0.9219\n",
      "<<aggregate_mean>> [f1] 0.8634, [precision] 0.8356, [recall] 0.9505\n",
      "<<aggregate_min>> [f1] 0.8775, [precision] 0.8741, [recall] 0.9284\n",
      "<<aggregate_max>> [f1] 0.798, [precision] 0.7332, [recall] 0.9646\n",
      "=========================================================\n",
      "THRESHOLD: 0.41000000000000003\n",
      "model=bert_indonesian [f1] 0.8468, [precision] 0.8185, [recall] 0.9398\n",
      "model=distilbert_base [f1] 0.8515, [precision] 0.8252, [recall] 0.9398\n",
      "model=bert_base [f1] 0.847, [precision] 0.8134, [recall] 0.9459\n",
      "<<<ensemble_ANY>>>: [f1] 0.8102, [precision] 0.7494, [recall] 0.9638\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.865, [precision] 0.846, [recall] 0.9443\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8771, [precision] 0.8919, [recall] 0.9175\n",
      "<<<ensemble_ALL>>>: [f1] 0.8771, [precision] 0.8919, [recall] 0.9175\n",
      "<<aggregate_mean>> [f1] 0.8693, [precision] 0.8468, [recall] 0.9473\n",
      "<<aggregate_min>> [f1] 0.8789, [precision] 0.8798, [recall] 0.9243\n",
      "<<aggregate_max>> [f1] 0.813, [precision] 0.7557, [recall] 0.9617\n",
      "=========================================================\n",
      "THRESHOLD: 0.42000000000000004\n",
      "model=bert_indonesian [f1] 0.8543, [precision] 0.8321, [recall] 0.9366\n",
      "model=distilbert_base [f1] 0.8571, [precision] 0.8363, [recall] 0.9358\n",
      "model=bert_base [f1] 0.855, [precision] 0.8278, [recall] 0.9424\n",
      "<<<ensemble_ANY>>>: [f1] 0.8238, [precision] 0.7695, [recall] 0.9613\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8703, [precision] 0.8566, [recall] 0.9409\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.878, [precision] 0.8982, [recall] 0.9125\n",
      "<<<ensemble_ALL>>>: [f1] 0.878, [precision] 0.8982, [recall] 0.9125\n",
      "<<aggregate_mean>> [f1] 0.8733, [precision] 0.8557, [recall] 0.9435\n",
      "<<aggregate_min>> [f1] 0.8802, [precision] 0.8859, [recall] 0.9199\n",
      "<<aggregate_max>> [f1] 0.8266, [precision] 0.7763, [recall] 0.9589\n",
      "=========================================================\n",
      "THRESHOLD: 0.43000000000000005\n",
      "model=bert_indonesian [f1] 0.8604, [precision] 0.8438, [recall] 0.9331\n",
      "model=distilbert_base [f1] 0.8619, [precision] 0.8466, [recall] 0.9322\n",
      "model=bert_base [f1] 0.8607, [precision] 0.839, [recall] 0.9386\n",
      "<<<ensemble_ANY>>>: [f1] 0.8352, [precision] 0.7866, [recall] 0.9592\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8731, [precision] 0.8647, [recall] 0.9367\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8793, [precision] 0.9047, [recall] 0.9082\n",
      "<<<ensemble_ALL>>>: [f1] 0.8793, [precision] 0.9047, [recall] 0.9082\n",
      "<<aggregate_mean>> [f1] 0.8758, [precision] 0.8633, [recall] 0.9392\n",
      "<<aggregate_min>> [f1] 0.8817, [precision] 0.8919, [recall] 0.916\n",
      "<<aggregate_max>> [f1] 0.8381, [precision] 0.794, [recall] 0.9565\n",
      "=========================================================\n",
      "THRESHOLD: 0.44000000000000006\n",
      "model=bert_indonesian [f1] 0.8638, [precision] 0.8527, [recall] 0.9286\n",
      "model=distilbert_base [f1] 0.8665, [precision] 0.8563, [recall] 0.9286\n",
      "model=bert_base [f1] 0.8658, [precision] 0.8498, [recall] 0.9349\n",
      "<<<ensemble_ANY>>>: [f1] 0.8441, [precision] 0.8015, [recall] 0.9562\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8768, [precision] 0.8737, [recall] 0.933\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8786, [precision] 0.9092, [recall] 0.9028\n",
      "<<<ensemble_ALL>>>: [f1] 0.8786, [precision] 0.9092, [recall] 0.9028\n",
      "<<aggregate_mean>> [f1] 0.8785, [precision] 0.8709, [recall] 0.9352\n",
      "<<aggregate_min>> [f1] 0.8816, [precision] 0.8961, [recall] 0.9114\n",
      "<<aggregate_max>> [f1] 0.847, [precision] 0.8093, [recall] 0.953\n",
      "=========================================================\n",
      "THRESHOLD: 0.45000000000000007\n",
      "model=bert_indonesian [f1] 0.8679, [precision] 0.8621, [recall] 0.9246\n",
      "model=distilbert_base [f1] 0.8695, [precision] 0.8645, [recall] 0.9243\n",
      "model=bert_base [f1] 0.8701, [precision] 0.8598, [recall] 0.9309\n",
      "<<<ensemble_ANY>>>: [f1] 0.8525, [precision] 0.8154, [recall] 0.9532\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8789, [precision] 0.8808, [recall] 0.9287\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8787, [precision] 0.9141, [recall] 0.8979\n",
      "<<<ensemble_ALL>>>: [f1] 0.8787, [precision] 0.9141, [recall] 0.8979\n",
      "<<aggregate_mean>> [f1] 0.8808, [precision] 0.878, [recall] 0.931\n",
      "<<aggregate_min>> [f1] 0.882, [precision] 0.9007, [recall] 0.9071\n",
      "<<aggregate_max>> [f1] 0.8555, [precision] 0.8238, [recall] 0.9496\n",
      "=========================================================\n",
      "THRESHOLD: 0.4600000000000001\n",
      "model=bert_indonesian [f1] 0.8705, [precision] 0.8695, [recall] 0.9206\n",
      "model=distilbert_base [f1] 0.8726, [precision] 0.8719, [recall] 0.9212\n",
      "model=bert_base [f1] 0.8734, [precision] 0.8682, [recall] 0.9266\n",
      "<<<ensemble_ANY>>>: [f1] 0.8594, [precision] 0.8275, [recall] 0.9503\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.881, [precision] 0.8878, [recall] 0.9248\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.878, [precision] 0.9177, [recall] 0.8932\n",
      "<<<ensemble_ALL>>>: [f1] 0.878, [precision] 0.9177, [recall] 0.8932\n",
      "<<aggregate_mean>> [f1] 0.883, [precision] 0.885, [recall] 0.9266\n",
      "<<aggregate_min>> [f1] 0.8816, [precision] 0.9039, [recall] 0.9028\n",
      "<<aggregate_max>> [f1] 0.8624, [precision] 0.8365, [recall] 0.9462\n",
      "=========================================================\n",
      "THRESHOLD: 0.4700000000000001\n",
      "model=bert_indonesian [f1] 0.8729, [precision] 0.8769, [recall] 0.9168\n",
      "model=distilbert_base [f1] 0.8743, [precision] 0.8789, [recall] 0.9165\n",
      "model=bert_base [f1] 0.8758, [precision] 0.8756, [recall] 0.9224\n",
      "<<<ensemble_ANY>>>: [f1] 0.8646, [precision] 0.8381, [recall] 0.9468\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8826, [precision] 0.8942, [recall] 0.9204\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8775, [precision] 0.9223, [recall] 0.8885\n",
      "<<<ensemble_ALL>>>: [f1] 0.8775, [precision] 0.9223, [recall] 0.8885\n",
      "<<aggregate_mean>> [f1] 0.8847, [precision] 0.8913, [recall] 0.9228\n",
      "<<aggregate_min>> [f1] 0.8812, [precision] 0.908, [recall] 0.8984\n",
      "<<aggregate_max>> [f1] 0.8675, [precision] 0.8473, [recall] 0.9422\n",
      "=========================================================\n",
      "THRESHOLD: 0.4800000000000001\n",
      "model=bert_indonesian [f1] 0.8743, [precision] 0.8832, [recall] 0.9117\n",
      "model=distilbert_base [f1] 0.8754, [precision] 0.8845, [recall] 0.9122\n",
      "model=bert_base [f1] 0.8783, [precision] 0.8831, [recall] 0.9187\n",
      "<<<ensemble_ANY>>>: [f1] 0.8695, [precision] 0.8481, [recall] 0.9434\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8834, [precision] 0.8997, [recall] 0.916\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8762, [precision] 0.9262, [recall] 0.8831\n",
      "<<<ensemble_ALL>>>: [f1] 0.8762, [precision] 0.9262, [recall] 0.8831\n",
      "<<aggregate_mean>> [f1] 0.8852, [precision] 0.8964, [recall] 0.9181\n",
      "<<aggregate_min>> [f1] 0.8802, [precision] 0.9111, [recall] 0.8935\n",
      "<<aggregate_max>> [f1] 0.8725, [precision] 0.858, [recall] 0.9386\n",
      "=========================================================\n",
      "THRESHOLD: 0.4900000000000001\n",
      "model=bert_indonesian [f1] 0.8752, [precision] 0.8885, [recall] 0.9074\n",
      "model=distilbert_base [f1] 0.8756, [precision] 0.8897, [recall] 0.9073\n",
      "model=bert_base [f1] 0.8794, [precision] 0.8885, [recall] 0.9148\n",
      "<<<ensemble_ANY>>>: [f1] 0.8723, [precision] 0.8556, [recall] 0.9393\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.884, [precision] 0.9047, [recall] 0.9118\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8749, [precision] 0.9294, [recall] 0.8784\n",
      "<<<ensemble_ALL>>>: [f1] 0.8749, [precision] 0.9294, [recall] 0.8784\n",
      "<<aggregate_mean>> [f1] 0.8855, [precision] 0.9009, [recall] 0.914\n",
      "<<aggregate_min>> [f1] 0.879, [precision] 0.9141, [recall] 0.8889\n",
      "<<aggregate_max>> [f1] 0.8753, [precision] 0.866, [recall] 0.9342\n",
      "=========================================================\n",
      "THRESHOLD: 0.5000000000000001\n",
      "model=bert_indonesian [f1] 0.8753, [precision] 0.8927, [recall] 0.9032\n",
      "model=distilbert_base [f1] 0.8763, [precision] 0.8951, [recall] 0.9027\n",
      "model=bert_base [f1] 0.8797, [precision] 0.8936, [recall] 0.91\n",
      "<<<ensemble_ANY>>>: [f1] 0.8747, [precision] 0.8627, [recall] 0.9354\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8841, [precision] 0.9091, [recall] 0.9076\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8733, [precision] 0.9329, [recall] 0.8729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<ensemble_ALL>>>: [f1] 0.8733, [precision] 0.9329, [recall] 0.8729\n",
      "<<aggregate_mean>> [f1] 0.8856, [precision] 0.9049, [recall] 0.9098\n",
      "<<aggregate_min>> [f1] 0.8777, [precision] 0.9171, [recall] 0.8839\n",
      "<<aggregate_max>> [f1] 0.8777, [precision] 0.8736, [recall] 0.9299\n",
      "=========================================================\n",
      "THRESHOLD: 0.5100000000000001\n",
      "model=bert_indonesian [f1] 0.8757, [precision] 0.8975, [recall] 0.8988\n",
      "model=distilbert_base [f1] 0.8766, [precision] 0.9003, [recall] 0.8976\n",
      "model=bert_base [f1] 0.8802, [precision] 0.8985, [recall] 0.9059\n",
      "<<<ensemble_ANY>>>: [f1] 0.8767, [precision] 0.8689, [recall] 0.9319\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8842, [precision] 0.9138, [recall] 0.9028\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.872, [precision] 0.9367, [recall] 0.8675\n",
      "<<<ensemble_ALL>>>: [f1] 0.872, [precision] 0.9367, [recall] 0.8675\n",
      "<<aggregate_mean>> [f1] 0.8849, [precision] 0.9081, [recall] 0.9055\n",
      "<<aggregate_min>> [f1] 0.8767, [precision] 0.9207, [recall] 0.8789\n",
      "<<aggregate_max>> [f1] 0.8797, [precision] 0.88, [recall] 0.9261\n",
      "=========================================================\n",
      "THRESHOLD: 0.5200000000000001\n",
      "model=bert_indonesian [f1] 0.8748, [precision] 0.9014, [recall] 0.8937\n",
      "model=distilbert_base [f1] 0.8768, [precision] 0.9047, [recall] 0.8932\n",
      "model=bert_base [f1] 0.8803, [precision] 0.903, [recall] 0.9015\n",
      "<<<ensemble_ANY>>>: [f1] 0.8784, [precision] 0.8749, [recall] 0.9282\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8833, [precision] 0.917, [recall] 0.8982\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8702, [precision] 0.9402, [recall] 0.8622\n",
      "<<<ensemble_ALL>>>: [f1] 0.8702, [precision] 0.9402, [recall] 0.8622\n",
      "<<aggregate_mean>> [f1] 0.8842, [precision] 0.912, [recall] 0.9006\n",
      "<<aggregate_min>> [f1] 0.8753, [precision] 0.9236, [recall] 0.8742\n",
      "<<aggregate_max>> [f1] 0.8812, [precision] 0.8864, [recall] 0.9219\n",
      "=========================================================\n",
      "THRESHOLD: 0.5300000000000001\n",
      "model=bert_indonesian [f1] 0.8742, [precision] 0.9051, [recall] 0.8894\n",
      "model=distilbert_base [f1] 0.8765, [precision] 0.9091, [recall] 0.8887\n",
      "model=bert_base [f1] 0.8803, [precision] 0.9073, [recall] 0.8974\n",
      "<<<ensemble_ANY>>>: [f1] 0.8799, [precision] 0.8806, [recall] 0.9246\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8828, [precision] 0.921, [recall] 0.8938\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8682, [precision] 0.9428, [recall] 0.857\n",
      "<<<ensemble_ALL>>>: [f1] 0.8682, [precision] 0.9428, [recall] 0.857\n",
      "<<aggregate_mean>> [f1] 0.8837, [precision] 0.9157, [recall] 0.8964\n",
      "<<aggregate_min>> [f1] 0.8735, [precision] 0.926, [recall] 0.8694\n",
      "<<aggregate_max>> [f1] 0.8826, [precision] 0.8923, [recall] 0.9181\n",
      "=========================================================\n",
      "THRESHOLD: 0.5400000000000001\n",
      "model=bert_indonesian [f1] 0.8731, [precision] 0.9088, [recall] 0.8839\n",
      "model=distilbert_base [f1] 0.8761, [precision] 0.9129, [recall] 0.8845\n",
      "model=bert_base [f1] 0.8793, [precision] 0.9109, [recall] 0.892\n",
      "<<<ensemble_ANY>>>: [f1] 0.8804, [precision] 0.8855, [recall] 0.9202\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8822, [precision] 0.9246, [recall] 0.8892\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8655, [precision] 0.9456, [recall] 0.8511\n",
      "<<<ensemble_ALL>>>: [f1] 0.8655, [precision] 0.9456, [recall] 0.8511\n",
      "<<aggregate_mean>> [f1] 0.8821, [precision] 0.9188, [recall] 0.8911\n",
      "<<aggregate_min>> [f1] 0.8712, [precision] 0.9282, [recall] 0.864\n",
      "<<aggregate_max>> [f1] 0.8831, [precision] 0.8975, [recall] 0.9134\n",
      "=========================================================\n",
      "THRESHOLD: 0.5500000000000002\n",
      "model=bert_indonesian [f1] 0.8718, [precision] 0.9116, [recall] 0.8789\n",
      "model=distilbert_base [f1] 0.8754, [precision] 0.9165, [recall] 0.8799\n",
      "model=bert_base [f1] 0.8775, [precision] 0.9143, [recall] 0.8857\n",
      "<<<ensemble_ANY>>>: [f1] 0.8808, [precision] 0.8901, [recall] 0.9157\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8806, [precision] 0.9275, [recall] 0.8839\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8626, [precision] 0.9479, [recall] 0.8449\n",
      "<<<ensemble_ALL>>>: [f1] 0.8626, [precision] 0.9479, [recall] 0.8449\n",
      "<<aggregate_mean>> [f1] 0.881, [precision] 0.9223, [recall] 0.8862\n",
      "<<aggregate_min>> [f1] 0.8687, [precision] 0.9302, [recall] 0.8583\n",
      "<<aggregate_max>> [f1] 0.8835, [precision] 0.9023, [recall] 0.9086\n"
     ]
    }
   ],
   "source": [
    "df_result = []\n",
    "for th in np.arange(0.4, 0.55, 0.01):\n",
    "    print(\"=========================================================\")\n",
    "    print(f\"THRESHOLD: {th}\")\n",
    "    for model_name in model_dict.keys():\n",
    "        f1score, precision, recall = get_cv(df, \n",
    "                                            model_dist_dict[model_name][\"cosine_similarity\"],\n",
    "                                            th,\n",
    "                                            posting_id,\n",
    "                                            pred_name=model_name,\n",
    "                                            min_n=2,\n",
    "                                            mode=\"max\")\n",
    "        print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "    df[\"pred\"] = df.apply(combine_predictions_any, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ANY>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_major, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_major2, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_all, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ALL>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    for mode in [\"mean\", \"min\", \"max\"]:\n",
    "        f1score, precision, recall = get_cv(df,\n",
    "                                            aggregate_distance(model_dist_dict, mode=mode),\n",
    "                                            th,\n",
    "                                            posting_id,\n",
    "                                            pred_name=model_name,\n",
    "                                            min_n=2,\n",
    "                                            mode=\"max\")\n",
    "        print(f\"<<aggregate_{mode}>> [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
