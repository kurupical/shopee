{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import glob\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/shopee-product-matching/train_fold.csv\")\n",
    "df = df[df[\"fold\"] == 0]\n",
    "tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "df['target'] = df.label_group.map(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_id = df[\"posting_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(embeddings):\n",
    "\n",
    "    CHUNK = 1024 * 2\n",
    "    CTS = len(embeddings) // CHUNK\n",
    "    if (len(embeddings)%CHUNK) != 0:\n",
    "        CTS += 1\n",
    "    distances = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embeddings = normalize(embeddings)\n",
    "        embeddings = torch.tensor(embeddings).cuda()\n",
    "\n",
    "        for j in range( CTS ):\n",
    "            a = j * CHUNK\n",
    "            b = (j+1) * CHUNK\n",
    "            b = min(b, len(embeddings))\n",
    "            # print('chunk', a, 'to', b)\n",
    "\n",
    "            # COSINE SIMILARITY DISTANCE\n",
    "            cts = torch.matmul(embeddings, embeddings[a:b].T).T\n",
    "            distances.append(cts.detach().cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epochs(model_path, early_stopping_round=3):\n",
    "    file_len = len(glob.glob(f\"{model_path}/indices_epoch*.npy\"))\n",
    "    return file_len - early_stopping_round - 1 # epoch は0はじまりなのでさらに1ひく\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    \"bert\": \"../output/exp044/20210420161425\", # CV: 0.862\n",
    "    \"bert_indonesian\": \"../output/exp057_2/20210422215407\", # CV: 0.862\n",
    "    \"xlm_roberta\": \"../output/exp057/20210422123000\", # CV: 0.855\n",
    "    \"distilbert\": \"../output/exp057_3/20210423001437\", # CV: 0.855\n",
    "    \"bert_transformer\": \"../output/exp058_2/20210423035344\" # CV: 0.854,    \n",
    "}\n",
    "\n",
    "model_dist_dict = {}\n",
    "    \n",
    "for k, path in model_dict.items():\n",
    "    best_epochs = get_best_epochs(path)\n",
    "    \n",
    "    model_dist_dict[k] = {\n",
    "        \"distances\": np.load(f\"{path}/distances_epoch{best_epochs}.npy\"),\n",
    "        \"indices\": np.load(f\"{path}/indices_epoch{best_epochs}.npy\"),\n",
    "        \"embeddings\":  np.load(f\"{path}/embeddings_epoch{best_epochs}.npy\")\n",
    "    }\n",
    "    \n",
    "    model_dist_dict[k][\"cosine_similarity\"] = get_cosine_similarity(model_dist_dict[k][\"embeddings\"]).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(df, similarity_matrix, threshold, indices=None, pred_name=\"pred\", min_n=2, mode=\"min\"):\n",
    "    posting_id = df[\"posting_id\"].values\n",
    "    preds = []\n",
    "    for k in range(len(df)):\n",
    "        if mode == \"min\": # euclid distance etc\n",
    "            IDX = np.where(similarity_matrix[k, ] < threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "        if mode == \"max\": # cosine similarlity\n",
    "            IDX = np.where(similarity_matrix[k, ] > threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[-min_n:]\n",
    "            \n",
    "        if indices is None:\n",
    "            pred = posting_id[IDX]\n",
    "        else:\n",
    "            if len(IDX) < min_n:\n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "            idx = indices[k, IDX]\n",
    "            pred = posting_id[idx]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    df[pred_name] = preds\n",
    "    f1score, precision, recall = calc_cv(df, col_name=pred_name)\n",
    "    return f1score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv(df, col_name):\n",
    "    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    df['target'] = df.label_group.map(tmp)\n",
    "    df['f1'] = df.apply(get_f1(col_name),axis=1)\n",
    "    df[\"precision\"] = df.apply(get_precision(col_name), axis=1)\n",
    "    df[\"recall\"] = df.apply(get_recall(col_name), axis=1)\n",
    "    return df[\"f1\"].mean(), df[\"precision\"].mean(), df[\"recall\"].mean()\n",
    "\n",
    "def get_f1(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score\n",
    "\n",
    "def get_precision(col):\n",
    "    def precision_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        if len(row[col]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return n / len(row[col])\n",
    "    return precision_score\n",
    "\n",
    "def get_recall(col):\n",
    "    def recall_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return n / len(row.target)\n",
    "    return recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_any(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x = np.unique(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 1\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_all(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts == 3\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major2(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 2\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_cv(1件→2件むりやり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_distance(model_dist_dict, mode):\n",
    "    ary = []\n",
    "    \n",
    "    for k, v in model_dist_dict.items():\n",
    "        ary.append(model_dist_dict[k][\"cosine_similarity\"])\n",
    "    \n",
    "    ary = np.array(ary)\n",
    "    \n",
    "    if mode == \"min\":\n",
    "        ary = ary.min(axis=0)\n",
    "    if mode == \"mean\":\n",
    "        ary = ary.mean(axis=0)\n",
    "    if mode == \"max\":\n",
    "        ary = ary.max(axis=0)\n",
    "\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return -0.0045*x + 0.53\n",
    "    \n",
    "threshold_ary = [0, 0.4] + f(np.arange(48)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=bert [f1] 0.8645, [precision] 0.852, [recall] 0.9296\n",
      "model=bert_indonesian [f1] 0.8627, [precision] 0.8512, [recall] 0.9272\n",
      "model=xlm_roberta [f1] 0.8539, [precision] 0.8395, [recall] 0.9253\n",
      "model=distilbert [f1] 0.8655, [precision] 0.8534, [recall] 0.9309\n",
      "model=bert_transformer [f1] 0.8702, [precision] 0.8747, [recall] 0.9151\n",
      "model=bert [f1] 0.8439, [precision] 0.9418, [recall] 0.8112\n",
      "model=bert_indonesian [f1] 0.8352, [precision] 0.9376, [recall] 0.8006\n",
      "model=xlm_roberta [f1] 0.8318, [precision] 0.9427, [recall] 0.7912\n",
      "model=distilbert [f1] 0.8471, [precision] 0.937, [recall] 0.8177\n",
      "model=bert_transformer [f1] 0.8325, [precision] 0.9361, [recall] 0.7987\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_dict.keys():\n",
    "    f1score, precision, recall = get_cv(df, \n",
    "                                        \n",
    "                                        model_dist_dict[model_name][\"cosine_similarity\"],\n",
    "                                        0.45,\n",
    "                                        pred_name=f\"{model_name}_cossim\",\n",
    "                                        min_n=2,\n",
    "                                        mode=\"max\")\n",
    "    print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "\n",
    "for model_name in model_dict.keys():\n",
    "    if \"transformer\" in model_name:\n",
    "        th = 19\n",
    "    else:\n",
    "        th = 16\n",
    "    f1score, precision, recall = get_cv(df, \n",
    "                                         model_dist_dict[model_name][\"distances\"],\n",
    "                                         th,\n",
    "                                         indices=model_dist_dict[model_name][\"indices\"],\n",
    "                                         pred_name=f\"{model_name}_euclid\",\n",
    "                                         min_n=2,\n",
    "                                         mode=\"min\")\n",
    "    print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(x, n):\n",
    "    x = np.concatenate(x)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts >= n\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [x for x in df.columns if \"cossim\" in x or \"euclid\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<ensemble_vote_2>>>: [f1] 0.8638, [precision] 0.8357, [recall] 0.949\n",
      "<<<ensemble_vote_3>>>: [f1] 0.8809, [precision] 0.8741, [recall] 0.9365\n",
      "<<<ensemble_vote_4>>>: [f1] 0.8864, [precision] 0.8983, [recall] 0.9209\n",
      "<<<ensemble_vote_5>>>: [f1] 0.8854, [precision] 0.92, [recall] 0.8998\n",
      "<<<ensemble_vote_6>>>: [f1] 0.8731, [precision] 0.946, [recall] 0.8576\n",
      "<<<ensemble_vote_7>>>: [f1] 0.8592, [precision] 0.9573, [recall] 0.829\n",
      "<<<ensemble_vote_8>>>: [f1] 0.8429, [precision] 0.9653, [recall] 0.8012\n",
      "<<<ensemble_vote_9>>>: [f1] 0.8212, [precision] 0.9731, [recall] 0.7685\n"
     ]
    }
   ],
   "source": [
    "for n in [2, 3, 4, 5, 6, 7, 8, 9]:\n",
    "    df[\"pred\"] = [voting(x, n) for x in df[target_cols].values]\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_vote_{n}>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
