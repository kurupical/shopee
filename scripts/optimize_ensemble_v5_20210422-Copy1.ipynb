{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/shopee-product-matching/train_fold.csv\")\n",
    "df = df[df[\"fold\"] == 0]\n",
    "tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "df['target'] = df.label_group.map(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_id = df[\"posting_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(embeddings):\n",
    "    normed_emb = normalize(embeddings).astype(np.float16)\n",
    "    distances = np.matmul(normed_emb, normed_emb.T).T\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(df, similarity_matrix, threshold, posting_id, indices=None, pred_name=\"pred\", min_n=2, mode=\"min\"):\n",
    "    preds = []\n",
    "    for k in range(len(df)):\n",
    "        if mode == \"min\": # euclid distance etc\n",
    "            IDX = np.where(similarity_matrix[k, ] < threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "        if mode == \"max\": # cosine similarlity\n",
    "            IDX = np.where(similarity_matrix[k, ] > threshold)[0]\n",
    "            if len(IDX) < min_n:                \n",
    "                IDX = np.argsort(similarity_matrix[k, ])[-min_n:]\n",
    "            \n",
    "        pred = posting_id[IDX]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    df[pred_name] = preds\n",
    "    f1score, precision, recall = calc_cv(df, col_name=pred_name)\n",
    "    return f1score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv(df, col_name):\n",
    "    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    df['target'] = df.label_group.map(tmp)\n",
    "    df['f1'] = df.apply(get_f1(col_name),axis=1)\n",
    "    df[\"precision\"] = df.apply(get_precision(col_name), axis=1)\n",
    "    df[\"recall\"] = df.apply(get_recall(col_name), axis=1)\n",
    "    return df[\"f1\"].mean(), df[\"precision\"].mean(), df[\"recall\"].mean()\n",
    "\n",
    "def get_f1(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score\n",
    "\n",
    "def get_precision(col):\n",
    "    def precision_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        if len(row[col]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return n / len(row[col])\n",
    "    return precision_score\n",
    "\n",
    "def get_recall(col):\n",
    "    def recall_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return n / len(row.target)\n",
    "    return recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epochs(model_path, early_stopping_round=3):\n",
    "    file_len = len(glob.glob(f\"{model_path}/indices_epoch*.npy\"))\n",
    "    return file_len - early_stopping_round - 1 # epoch は0はじまりなのでさらに1ひく\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    \"bert\": \"../output/exp044/20210420161425\", # CV: 0.862\n",
    "    \"bert_indonesian\": \"../output/exp057_2/20210422215407\", # CV: 0.847\n",
    "    \"xlm_roberta\": \"../output/exp057/20210422123000\", # CV: 0.855\n",
    "    \"distilbert\": \"../output/exp057_3/20210423001437\", # CV: 0.857\n",
    "    \"bert_transformer\": \"../output/exp058_2/20210423035344\" # CV: 0.854,    \n",
    "}\n",
    "\n",
    "model_dist_dict = {}\n",
    "    \n",
    "for k, path in model_dict.items():\n",
    "    best_epochs = get_best_epochs(path)\n",
    "    \n",
    "    model_dist_dict[k] = {\n",
    "        \"distances\": np.load(f\"{path}/distances_epoch{best_epochs}.npy\"),\n",
    "        \"indices\": np.load(f\"{path}/indices_epoch{best_epochs}.npy\"),\n",
    "        \"embeddings\":  np.load(f\"{path}/embeddings_epoch{best_epochs}.npy\")\n",
    "    }\n",
    "    \n",
    "    model_dist_dict[k][\"cosine_similarity\"] = get_cosine_similarity(model_dist_dict[k][\"embeddings\"]).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_any(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x = np.unique(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 1\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_all(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts == 3\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major2(row):\n",
    "    x = np.concatenate(row[model_dict.keys()].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 2\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_cv(1件→2件むりやり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_distance(model_dist_dict, mode):\n",
    "    ary = []\n",
    "    \n",
    "    for k, v in model_dist_dict.items():\n",
    "        ary.append(model_dist_dict[k][\"cosine_similarity\"])\n",
    "    \n",
    "    ary = np.array(ary)\n",
    "    \n",
    "    if mode == \"min\":\n",
    "        ary = ary.min(axis=0)\n",
    "    if mode == \"mean\":\n",
    "        ary = ary.mean(axis=0)\n",
    "    if mode == \"max\":\n",
    "        ary = ary.max(axis=0)\n",
    "\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "THRESHOLD: 0.47\n",
      "model=bert [f1] 0.8711, [precision] 0.8688, [recall] 0.9218\n",
      "model=bert_indonesian [f1] 0.8696, [precision] 0.8675, [recall] 0.9202\n",
      "model=xlm_roberta [f1] 0.8627, [precision] 0.8594, [recall] 0.9174\n",
      "model=distilbert [f1] 0.8731, [precision] 0.871, [recall] 0.9239\n",
      "model=bert_transformer [f1] 0.8724, [precision] 0.8872, [recall] 0.9057\n",
      "<<<ensemble_ANY>>>: [f1] 0.8415, [precision] 0.7962, [recall] 0.9587\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8762, [precision] 0.8644, [recall] 0.9393\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8849, [precision] 0.8963, [recall] 0.9227\n",
      "<<<ensemble_ALL>>>: [f1] 0.0321, [precision] 0.1005, [recall] 0.0213\n",
      "<<aggregate_mean>> [f1] 0.886, [precision] 0.8916, [recall] 0.9248\n",
      "<<aggregate_min>> [f1] 0.8778, [precision] 0.9204, [recall] 0.8833\n",
      "<<aggregate_max>> [f1] 0.8472, [precision] 0.809, [recall] 0.9535\n",
      "=========================================================\n",
      "THRESHOLD: 0.48\n",
      "model=bert [f1] 0.8737, [precision] 0.8765, [recall] 0.9179\n",
      "model=bert_indonesian [f1] 0.8719, [precision] 0.8748, [recall] 0.916\n",
      "model=xlm_roberta [f1] 0.8663, [precision] 0.8682, [recall] 0.9136\n",
      "model=distilbert [f1] 0.8756, [precision] 0.8783, [recall] 0.9202\n",
      "model=bert_transformer [f1] 0.8732, [precision] 0.8932, [recall] 0.9012\n",
      "<<<ensemble_ANY>>>: [f1] 0.8494, [precision] 0.8097, [recall] 0.9556\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.88, [precision] 0.8728, [recall] 0.9361\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8857, [precision] 0.9024, [recall] 0.9185\n",
      "<<<ensemble_ALL>>>: [f1] 0.0323, [precision] 0.1005, [recall] 0.0212\n",
      "<<aggregate_mean>> [f1] 0.8871, [precision] 0.8973, [recall] 0.9206\n",
      "<<aggregate_min>> [f1] 0.8764, [precision] 0.9232, [recall] 0.8783\n",
      "<<aggregate_max>> [f1] 0.855, [precision] 0.8229, [recall] 0.9498\n",
      "=========================================================\n",
      "THRESHOLD: 0.49\n",
      "model=bert [f1] 0.8757, [precision] 0.8832, [recall] 0.914\n",
      "model=bert_indonesian [f1] 0.8742, [precision] 0.8816, [recall] 0.9124\n",
      "model=xlm_roberta [f1] 0.869, [precision] 0.8757, [recall] 0.9103\n",
      "model=distilbert [f1] 0.8771, [precision] 0.8846, [recall] 0.9159\n",
      "model=bert_transformer [f1] 0.8725, [precision] 0.8975, [recall] 0.8955\n",
      "<<<ensemble_ANY>>>: [f1] 0.8555, [precision] 0.8211, [recall] 0.9521\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8829, [precision] 0.8796, [recall] 0.9334\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8865, [precision] 0.9079, [recall] 0.9143\n",
      "<<<ensemble_ALL>>>: [f1] 0.0327, [precision] 0.1039, [recall] 0.0216\n",
      "<<aggregate_mean>> [f1] 0.8875, [precision] 0.9021, [recall] 0.9164\n",
      "<<aggregate_min>> [f1] 0.8746, [precision] 0.9258, [recall] 0.8729\n",
      "<<aggregate_max>> [f1] 0.8614, [precision] 0.8352, [recall] 0.9461\n",
      "=========================================================\n",
      "THRESHOLD: 0.5\n",
      "model=bert [f1] 0.8766, [precision] 0.8885, [recall] 0.9099\n",
      "model=bert_indonesian [f1] 0.876, [precision] 0.8884, [recall] 0.9083\n",
      "model=xlm_roberta [f1] 0.8708, [precision] 0.8827, [recall] 0.9058\n",
      "model=distilbert [f1] 0.8778, [precision] 0.8904, [recall] 0.9108\n",
      "model=bert_transformer [f1] 0.8722, [precision] 0.902, [recall] 0.8904\n",
      "<<<ensemble_ANY>>>: [f1] 0.8606, [precision] 0.8312, [recall] 0.9488\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8853, [precision] 0.8863, [recall] 0.9302\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8867, [precision] 0.913, [recall] 0.9096\n",
      "<<<ensemble_ALL>>>: [f1] 0.0343, [precision] 0.107, [recall] 0.0226\n",
      "<<aggregate_mean>> [f1] 0.8876, [precision] 0.9068, [recall] 0.9121\n",
      "<<aggregate_min>> [f1] 0.8727, [precision] 0.9286, [recall] 0.8676\n",
      "<<aggregate_max>> [f1] 0.8666, [precision] 0.8459, [recall] 0.9423\n",
      "=========================================================\n",
      "THRESHOLD: 0.51\n",
      "model=bert [f1] 0.8777, [precision] 0.8942, [recall] 0.9059\n",
      "model=bert_indonesian [f1] 0.8766, [precision] 0.8938, [recall] 0.9039\n",
      "model=xlm_roberta [f1] 0.8719, [precision] 0.889, [recall] 0.9012\n",
      "model=distilbert [f1] 0.8786, [precision] 0.8962, [recall] 0.9062\n",
      "model=bert_transformer [f1] 0.8716, [precision] 0.9068, [recall] 0.885\n",
      "<<<ensemble_ANY>>>: [f1] 0.8652, [precision] 0.8405, [recall] 0.9455\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.887, [precision] 0.8925, [recall] 0.9263\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.887, [precision] 0.918, [recall] 0.9052\n",
      "<<<ensemble_ALL>>>: [f1] 0.0354, [precision] 0.1149, [recall] 0.0231\n",
      "<<aggregate_mean>> [f1] 0.8875, [precision] 0.9117, [recall] 0.9071\n",
      "<<aggregate_min>> [f1] 0.87, [precision] 0.9312, [recall] 0.8614\n",
      "<<aggregate_max>> [f1] 0.8712, [precision] 0.8557, [recall] 0.9385\n",
      "=========================================================\n",
      "THRESHOLD: 0.52\n",
      "model=bert [f1] 0.8778, [precision] 0.8993, [recall] 0.9011\n",
      "model=bert_indonesian [f1] 0.8768, [precision] 0.8991, [recall] 0.899\n",
      "model=xlm_roberta [f1] 0.8739, [precision] 0.8955, [recall] 0.8978\n",
      "model=distilbert [f1] 0.8788, [precision] 0.9008, [recall] 0.902\n",
      "model=bert_transformer [f1] 0.8701, [precision] 0.9106, [recall] 0.879\n",
      "<<<ensemble_ANY>>>: [f1] 0.8695, [precision] 0.8491, [recall] 0.9427\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.888, [precision] 0.8981, [recall] 0.9219\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8865, [precision] 0.9223, [recall] 0.9004\n",
      "<<<ensemble_ALL>>>: [f1] 0.0356, [precision] 0.1153, [recall] 0.0231\n",
      "<<aggregate_mean>> [f1] 0.8871, [precision] 0.9157, [recall] 0.9026\n",
      "<<aggregate_min>> [f1] 0.8675, [precision] 0.9334, [recall] 0.8558\n",
      "<<aggregate_max>> [f1] 0.8756, [precision] 0.8652, [recall] 0.9353\n",
      "=========================================================\n",
      "THRESHOLD: 0.53\n",
      "model=bert [f1] 0.878, [precision] 0.9039, [recall] 0.8967\n",
      "model=bert_indonesian [f1] 0.8762, [precision] 0.9031, [recall] 0.8942\n",
      "model=xlm_roberta [f1] 0.8747, [precision] 0.9014, [recall] 0.8932\n",
      "model=distilbert [f1] 0.8787, [precision] 0.905, [recall] 0.8978\n",
      "model=bert_transformer [f1] 0.8681, [precision] 0.9138, [recall] 0.873\n",
      "<<<ensemble_ANY>>>: [f1] 0.8724, [precision] 0.8561, [recall] 0.9397\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8883, [precision] 0.9029, [recall] 0.9175\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8859, [precision] 0.9263, [recall] 0.8956\n",
      "<<<ensemble_ALL>>>: [f1] 0.0362, [precision] 0.1171, [recall] 0.0234\n",
      "<<aggregate_mean>> [f1] 0.8853, [precision] 0.9185, [recall] 0.8971\n",
      "<<aggregate_min>> [f1] 0.8646, [precision] 0.9352, [recall] 0.8498\n",
      "<<aggregate_max>> [f1] 0.8785, [precision] 0.8726, [recall] 0.9318\n",
      "=========================================================\n",
      "THRESHOLD: 0.54\n",
      "model=bert [f1] 0.8774, [precision] 0.9087, [recall] 0.8914\n",
      "model=bert_indonesian [f1] 0.8759, [precision] 0.9072, [recall] 0.8895\n",
      "model=xlm_roberta [f1] 0.8748, [precision] 0.9063, [recall] 0.8885\n",
      "model=distilbert [f1] 0.8786, [precision] 0.9093, [recall] 0.8934\n",
      "model=bert_transformer [f1] 0.8668, [precision] 0.9172, [recall] 0.868\n",
      "<<<ensemble_ANY>>>: [f1] 0.8756, [precision] 0.8636, [recall] 0.9364\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8892, [precision] 0.9081, [recall] 0.914\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8848, [precision] 0.9298, [recall] 0.8909\n",
      "<<<ensemble_ALL>>>: [f1] 0.0382, [precision] 0.1225, [recall] 0.0247\n",
      "<<aggregate_mean>> [f1] 0.8841, [precision] 0.9219, [recall] 0.8921\n",
      "<<aggregate_min>> [f1] 0.862, [precision] 0.9376, [recall] 0.8438\n",
      "<<aggregate_max>> [f1] 0.8816, [precision] 0.8807, [recall] 0.9279\n",
      "=========================================================\n",
      "THRESHOLD: 0.55\n",
      "model=bert [f1] 0.8758, [precision] 0.9114, [recall] 0.8863\n",
      "model=bert_indonesian [f1] 0.8744, [precision] 0.9105, [recall] 0.8839\n",
      "model=xlm_roberta [f1] 0.8744, [precision] 0.9112, [recall] 0.8831\n",
      "model=distilbert [f1] 0.8775, [precision] 0.9125, [recall] 0.8888\n",
      "model=bert_transformer [f1] 0.8647, [precision] 0.9195, [recall] 0.8625\n",
      "<<<ensemble_ANY>>>: [f1] 0.878, [precision] 0.8702, [recall] 0.933\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.888, [precision] 0.9114, [recall] 0.9087\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8823, [precision] 0.9319, [recall] 0.8853\n",
      "<<<ensemble_ALL>>>: [f1] 0.0386, [precision] 0.1238, [recall] 0.025\n",
      "<<aggregate_mean>> [f1] 0.882, [precision] 0.9241, [recall] 0.8869\n",
      "<<aggregate_min>> [f1] 0.859, [precision] 0.939, [recall] 0.8384\n",
      "<<aggregate_max>> [f1] 0.8836, [precision] 0.8875, [recall] 0.9236\n"
     ]
    }
   ],
   "source": [
    "df_result = []\n",
    "for th in np.arange(0.47, 0.55, 0.01):\n",
    "    print(\"=========================================================\")\n",
    "    print(f\"THRESHOLD: {th}\")\n",
    "    for model_name in model_dict.keys():\n",
    "        f1score, precision, recall = get_cv(df, \n",
    "                                            model_dist_dict[model_name][\"cosine_similarity\"],\n",
    "                                            th,\n",
    "                                            posting_id,\n",
    "                                            pred_name=model_name,\n",
    "                                            min_n=2,\n",
    "                                            mode=\"max\")\n",
    "        print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "    df[\"pred\"] = df.apply(combine_predictions_any, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ANY>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_major, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_major2, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_all, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ALL>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    for mode in [\"mean\", \"min\", \"max\"]:\n",
    "        f1score, precision, recall = get_cv(df,\n",
    "                                            aggregate_distance(model_dist_dict, mode=mode),\n",
    "                                            th,\n",
    "                                            posting_id,\n",
    "                                            pred_name=model_name,\n",
    "                                            min_n=2,\n",
    "                                            mode=\"max\")\n",
    "        print(f\"<<aggregate_{mode}>> [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(df, similarity_matrix, threshold, posting_id, indices=None, pred_name=\"pred\", min_n=2):\n",
    "    preds = []\n",
    "    for k in range(len(df)):\n",
    "        IDX = np.where(similarity_matrix[k, ] < threshold)[0]\n",
    "        if indices is None:\n",
    "            pred = posting_id[IDX]\n",
    "        else:\n",
    "            if len(IDX) < min_n:\n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "            idx = indices[k, IDX]\n",
    "            pred = posting_id[idx]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    df[pred_name] = preds\n",
    "    f1score, precision, recall = calc_cv(df, col_name=pred_name)\n",
    "    return f1score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major2(row):\n",
    "    cossim = [f\"{x}_cos\" for x in model_dict.keys()]\n",
    "    knn = [f\"{x}_knn\" for x in model_dict.keys()]\n",
    "    x = np.concatenate(row[cossim + knn].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 2\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major3(row):\n",
    "    cossim = [f\"{x}_cos\" for x in model_dict.keys()]\n",
    "    knn = [f\"{x}_knn\" for x in model_dict.keys()]\n",
    "    x = np.concatenate(row[cossim + knn].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 3\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major4(row):\n",
    "    cossim = [f\"{x}_cos\" for x in model_dict.keys()]\n",
    "    knn = [f\"{x}_knn\" for x in model_dict.keys()]\n",
    "    x = np.concatenate(row[cossim + knn].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 4\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major5(row):\n",
    "    cossim = [f\"{x}_cos\" for x in model_dict.keys()]\n",
    "    knn = [f\"{x}_knn\" for x in model_dict.keys()]\n",
    "    x = np.concatenate(row[cossim + knn].values)\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 5\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=bert [f1] 0.8774, [precision] 0.9087, [recall] 0.8914\n",
      "model=bert [f1] 0.8721, [precision] 0.9121, [recall] 0.8785\n",
      "model=bert_indonesian [f1] 0.8759, [precision] 0.9072, [recall] 0.8895\n",
      "model=bert_indonesian [f1] 0.8645, [precision] 0.9096, [recall] 0.8683\n",
      "model=xlm_roberta [f1] 0.8748, [precision] 0.9063, [recall] 0.8885\n",
      "model=xlm_roberta [f1] 0.8635, [precision] 0.9209, [recall] 0.8551\n",
      "model=distilbert [f1] 0.8786, [precision] 0.9093, [recall] 0.8934\n",
      "model=distilbert [f1] 0.8679, [precision] 0.8982, [recall] 0.8854\n",
      "model=bert_transformer [f1] 0.8668, [precision] 0.9172, [recall] 0.868\n",
      "model=bert_transformer [f1] 0.8622, [precision] 0.8953, [recall] 0.8795\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8883, [precision] 0.9028, [recall] 0.9182\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8884, [precision] 0.9177, [recall] 0.9053\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8853, [precision] 0.9288, [recall] 0.8918\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8811, [precision] 0.938, [recall] 0.8788\n"
     ]
    }
   ],
   "source": [
    "df_result = []\n",
    "for model_name in model_dict.keys():\n",
    "    f1score, precision, recall = get_cv(df, \n",
    "                                        model_dist_dict[model_name][\"cosine_similarity\"],\n",
    "                                        0.54,\n",
    "                                        posting_id,\n",
    "                                        pred_name=f\"{model_name}_cos\",\n",
    "                                        min_n=2,\n",
    "                                        mode=\"max\")\n",
    "    print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    if model_name == \"bert_transformer\":\n",
    "        th = 22\n",
    "    else:\n",
    "        th = 18.5\n",
    "    f1score, precision, recall = get_cv(df, \n",
    "                                        model_dist_dict[model_name][\"distances\"],\n",
    "                                        th,\n",
    "                                        posting_id,\n",
    "                                        model_dist_dict[model_name][\"indices\"],\n",
    "                                        pred_name=f\"{model_name}_knn\",\n",
    "                                        min_n=2,\n",
    "                                        mode=\"min\")\n",
    "    print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "\n",
    "df[\"pred\"] = df.apply(combine_predictions_major2, axis=1)\n",
    "f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "df[\"pred\"] = df.apply(combine_predictions_major3, axis=1)\n",
    "f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "df[\"pred\"] = df.apply(combine_predictions_major4, axis=1)\n",
    "f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "df[\"pred\"] = df.apply(combine_predictions_major5, axis=1)\n",
    "f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_knn</th>\n",
       "      <th>bert_cos</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[train_2865605743, train_1382500866]</td>\n",
       "      <td>[train_1382500866, train_2865605743]</td>\n",
       "      <td>[train_2865605743, train_1382500866]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[train_1382500866, train_3251720961]</td>\n",
       "      <td>[train_2865605743, train_1382500866]</td>\n",
       "      <td>[train_2865605743, train_1382500866]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[train_256668053, train_859155235]</td>\n",
       "      <td>[train_256668053, train_859155235]</td>\n",
       "      <td>[train_256668053, train_859155235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[train_859155235, train_256668053]</td>\n",
       "      <td>[train_256668053, train_859155235]</td>\n",
       "      <td>[train_256668053, train_859155235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[train_913614970, train_4292360632]</td>\n",
       "      <td>[train_4292360632, train_913614970]</td>\n",
       "      <td>[train_913614970, train_4292360632]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34092</th>\n",
       "      <td>[train_4199111972, train_3454652975, train_515...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_293...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34093</th>\n",
       "      <td>[train_2114123891, train_1699906038, train_395...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_515...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34094</th>\n",
       "      <td>[train_4178955354, train_112182868, train_2401...</td>\n",
       "      <td>[train_3497907844, train_515008716, train_3480...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34095</th>\n",
       "      <td>[train_112182868, train_4178955354, train_2401...</td>\n",
       "      <td>[train_3497907844, train_515008716, train_1354...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_293...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34096</th>\n",
       "      <td>[train_3668806308, train_2123729460, train_169...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_293...</td>\n",
       "      <td>[train_3497907844, train_4175229751, train_293...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6839 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                bert_knn  \\\n",
       "0                   [train_2865605743, train_1382500866]   \n",
       "1                   [train_1382500866, train_3251720961]   \n",
       "10                    [train_256668053, train_859155235]   \n",
       "11                    [train_859155235, train_256668053]   \n",
       "20                   [train_913614970, train_4292360632]   \n",
       "...                                                  ...   \n",
       "34092  [train_4199111972, train_3454652975, train_515...   \n",
       "34093  [train_2114123891, train_1699906038, train_395...   \n",
       "34094  [train_4178955354, train_112182868, train_2401...   \n",
       "34095  [train_112182868, train_4178955354, train_2401...   \n",
       "34096  [train_3668806308, train_2123729460, train_169...   \n",
       "\n",
       "                                                bert_cos  \\\n",
       "0                   [train_1382500866, train_2865605743]   \n",
       "1                   [train_2865605743, train_1382500866]   \n",
       "10                    [train_256668053, train_859155235]   \n",
       "11                    [train_256668053, train_859155235]   \n",
       "20                   [train_4292360632, train_913614970]   \n",
       "...                                                  ...   \n",
       "34092  [train_3497907844, train_4175229751, train_293...   \n",
       "34093  [train_3497907844, train_4175229751, train_515...   \n",
       "34094  [train_3497907844, train_515008716, train_3480...   \n",
       "34095  [train_3497907844, train_515008716, train_1354...   \n",
       "34096  [train_3497907844, train_4175229751, train_293...   \n",
       "\n",
       "                                                  target  \n",
       "0                   [train_2865605743, train_1382500866]  \n",
       "1                   [train_2865605743, train_1382500866]  \n",
       "10                    [train_256668053, train_859155235]  \n",
       "11                    [train_256668053, train_859155235]  \n",
       "20                   [train_913614970, train_4292360632]  \n",
       "...                                                  ...  \n",
       "34092  [train_3497907844, train_4175229751, train_293...  \n",
       "34093  [train_3497907844, train_4175229751, train_293...  \n",
       "34094  [train_3497907844, train_4175229751, train_293...  \n",
       "34095  [train_3497907844, train_4175229751, train_293...  \n",
       "34096  [train_3497907844, train_4175229751, train_293...  \n",
       "\n",
       "[6839 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"bert_knn\", \"bert_cos\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_distance(model_dist_dict, weight_ary):\n",
    "    ary = []\n",
    "    \n",
    "    for k, v in model_dist_dict.items():\n",
    "        ary.append(model_dist_dict[k][\"cosine_similarity\"])\n",
    "    \n",
    "    ary = np.array(ary)\n",
    "    ary = ary * np.array(weight_ary).reshape(-1, 1, 1) * np.array(weight_ary).sum()\n",
    "    return ary.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<aggregate_mean>> [f1] 0.0049, [precision] 0.0024, [recall] 0.9994\n"
     ]
    }
   ],
   "source": [
    "for mode in [\"mean\"]:\n",
    "    f1score, precision, recall = get_cv(df,\n",
    "                                        weight_distance(model_dist_dict, weight_ary=[1, 1, 1, 0.8, 0.8]),\n",
    "                                        0.54,\n",
    "                                        posting_id,\n",
    "                                        pred_name=model_name,\n",
    "                                        min_n=2,\n",
    "                                        mode=\"max\")\n",
    "    print(f\"<<aggregate_{mode}>> [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
