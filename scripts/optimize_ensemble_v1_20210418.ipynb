{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensembleを試したい\n",
    "* embeddingデータをとるのを忘れてしまった。。。ので、とりあえずはdistances, indicesから最適アンサンブルの閾値を探す。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/shopee-product-matching/train_fold.csv\")\n",
    "df = df[df[\"fold\"] == 0]\n",
    "tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "df['target'] = df.label_group.map(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posting_id = df[\"posting_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(df, similarity_matrix, threshold, posting_id, indices=None, pred_name=\"pred\", min_n=2):\n",
    "    preds = []\n",
    "    for k in range(len(df)):\n",
    "        IDX = np.where(similarity_matrix[k, ] < threshold)[0]\n",
    "        if indices is None:\n",
    "            pred = posting_id[IDX]\n",
    "        else:\n",
    "            if len(IDX) < min_n:\n",
    "                IDX = np.argsort(similarity_matrix[k, ])[:min_n]\n",
    "            idx = indices[k, IDX]\n",
    "            pred = posting_id[idx]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    df[pred_name] = preds\n",
    "    f1score, precision, recall = calc_cv(df, col_name=pred_name)\n",
    "    return f1score, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cv(df, col_name):\n",
    "    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
    "    df['target'] = df.label_group.map(tmp)\n",
    "    df['f1'] = df.apply(get_f1(col_name),axis=1)\n",
    "    df[\"precision\"] = df.apply(get_precision(col_name), axis=1)\n",
    "    df[\"recall\"] = df.apply(get_recall(col_name), axis=1)\n",
    "    return df[\"f1\"].mean(), df[\"precision\"].mean(), df[\"recall\"].mean()\n",
    "\n",
    "def get_f1(col):\n",
    "    def f1score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return 2*n / (len(row.target)+len(row[col]))\n",
    "    return f1score\n",
    "\n",
    "def get_precision(col):\n",
    "    def precision_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        if len(row[col]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return n / len(row[col])\n",
    "    return precision_score\n",
    "\n",
    "def get_recall(col):\n",
    "    def recall_score(row):\n",
    "        n = len( np.intersect1d(row.target,row[col]) )\n",
    "        return n / len(row.target)\n",
    "    return recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_epochs(model_path, early_stopping_round=3):\n",
    "    file_len = len(glob.glob(f\"{model_path}/indices_epoch*.npy\"))\n",
    "    return file_len - early_stopping_round - 1 # epoch は0はじまりなのでさらに1ひく\n",
    "\n",
    "\n",
    "model_dict = {\n",
    "    \"xlm_roberta_base\": \"../output/exp020/20210414065420\", # CV: 0.847\n",
    "    \"bert_indonesian\": \"../output/exp033/20210418043810\", # CV: 0.847\n",
    "    \"distilbert_base\": \"../output/exp033/20210418023429\", # CV: 0.852\n",
    "    \"bert_base\": \"../output/exp033/20210417225343\" # CV: 0.852\n",
    "}\n",
    "\n",
    "model_dist_dict = {}\n",
    "    \n",
    "for k, path in model_dict.items():\n",
    "    best_epochs = get_best_epochs(path)\n",
    "    \n",
    "    model_dist_dict[k] = {\n",
    "        \"distances\": np.load(f\"{path}/distances_epoch{best_epochs}.npy\"),\n",
    "        \"indices\": np.load(f\"{path}/indices_epoch{best_epochs}.npy\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_any(row):\n",
    "    x = np.concatenate([row['xlm_roberta_base'], row['distilbert_base'], row[\"bert_base\"], row[\"bert_indonesian\"]])\n",
    "    x = np.unique(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_major(row):\n",
    "    x = np.concatenate([row['xlm_roberta_base'], row['distilbert_base'], row[\"bert_base\"], row[\"bert_indonesian\"]])\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts > 1\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_predictions_all(row):\n",
    "    x = np.concatenate([row['xlm_roberta_base'], row['distilbert_base'], row[\"bert_base\"], row[\"bert_indonesian\"]])\n",
    "    x, counts = np.unique(x, return_counts=True)\n",
    "    \n",
    "    ret_idx = counts == 3\n",
    "    return x[ret_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_cv(1件→2件むりやり)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "THRESHOLD: 15.0\n",
      "model=xlm_roberta_base [f1] 0.8278, [precision] 0.9366, [recall] 0.7889\n",
      "model=bert_indonesian [f1] 0.8206, [precision] 0.9401, [recall] 0.7772\n",
      "model=distilbert_base [f1] 0.8163, [precision] 0.9428, [recall] 0.7693\n",
      "model=bert_base [f1] 0.8211, [precision] 0.9448, [recall] 0.7763\n",
      "<<<ensemble_ANY>>>: [f1] 0.8486, [precision] 0.9126, [recall] 0.8423\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8387, [precision] 0.9555, [recall] 0.7975\n",
      "<<<ensemble_ALL>>>: [f1] 0.0692, [precision] 0.1936, [recall] 0.0457\n",
      "=========================================================\n",
      "THRESHOLD: 15.5\n",
      "model=xlm_roberta_base [f1] 0.836, [precision] 0.9343, [recall] 0.8023\n",
      "model=bert_indonesian [f1] 0.8268, [precision] 0.9371, [recall] 0.7882\n",
      "model=distilbert_base [f1] 0.8255, [precision] 0.94, [recall] 0.7838\n",
      "model=bert_base [f1] 0.8293, [precision] 0.9424, [recall] 0.7892\n",
      "<<<ensemble_ANY>>>: [f1] 0.8553, [precision] 0.9091, [recall] 0.8553\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.847, [precision] 0.9528, [recall] 0.8112\n",
      "<<<ensemble_ALL>>>: [f1] 0.0715, [precision] 0.1988, [recall] 0.0472\n",
      "=========================================================\n",
      "THRESHOLD: 16.0\n",
      "model=xlm_roberta_base [f1] 0.8428, [precision] 0.9303, [recall] 0.8154\n",
      "model=bert_indonesian [f1] 0.8341, [precision] 0.9334, [recall] 0.801\n",
      "model=distilbert_base [f1] 0.8344, [precision] 0.937, [recall] 0.7982\n",
      "model=bert_base [f1] 0.8375, [precision] 0.9397, [recall] 0.8025\n",
      "<<<ensemble_ANY>>>: [f1] 0.8608, [precision] 0.9036, [recall] 0.8683\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8546, [precision] 0.9493, [recall] 0.8245\n",
      "<<<ensemble_ALL>>>: [f1] 0.0739, [precision] 0.2021, [recall] 0.0489\n",
      "=========================================================\n",
      "THRESHOLD: 16.5\n",
      "model=xlm_roberta_base [f1] 0.8487, [precision] 0.9249, [recall] 0.8287\n",
      "model=bert_indonesian [f1] 0.8409, [precision] 0.9292, [recall] 0.8136\n",
      "model=distilbert_base [f1] 0.8416, [precision] 0.933, [recall] 0.8111\n",
      "model=bert_base [f1] 0.8454, [precision] 0.9361, [recall] 0.8167\n",
      "<<<ensemble_ANY>>>: [f1] 0.8646, [precision] 0.8968, [recall] 0.8803\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8607, [precision] 0.9444, [recall] 0.8369\n",
      "<<<ensemble_ALL>>>: [f1] 0.0746, [precision] 0.2003, [recall] 0.0495\n",
      "=========================================================\n",
      "THRESHOLD: 17.0\n",
      "model=xlm_roberta_base [f1] 0.8536, [precision] 0.9184, [recall] 0.841\n",
      "model=bert_indonesian [f1] 0.8482, [precision] 0.9243, [recall] 0.8282\n",
      "model=distilbert_base [f1] 0.8487, [precision] 0.9288, [recall] 0.8247\n",
      "model=bert_base [f1] 0.8531, [precision] 0.9324, [recall] 0.8309\n",
      "<<<ensemble_ANY>>>: [f1] 0.8671, [precision] 0.8885, [recall] 0.8924\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8672, [precision] 0.939, [recall] 0.8507\n",
      "<<<ensemble_ALL>>>: [f1] 0.0723, [precision] 0.1922, [recall] 0.0482\n",
      "=========================================================\n",
      "THRESHOLD: 17.5\n",
      "model=xlm_roberta_base [f1] 0.8593, [precision] 0.9103, [recall] 0.8568\n",
      "model=bert_indonesian [f1] 0.8538, [precision] 0.9176, [recall] 0.8422\n",
      "model=distilbert_base [f1] 0.8554, [precision] 0.9236, [recall] 0.8392\n",
      "model=bert_base [f1] 0.8583, [precision] 0.9262, [recall] 0.8441\n",
      "<<<ensemble_ANY>>>: [f1] 0.8675, [precision] 0.8768, [recall] 0.905\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.873, [precision] 0.933, [recall] 0.865\n",
      "<<<ensemble_ALL>>>: [f1] 0.0716, [precision] 0.19, [recall] 0.048\n",
      "=========================================================\n",
      "THRESHOLD: 18.0\n",
      "model=xlm_roberta_base [f1] 0.8594, [precision] 0.8961, [recall] 0.8701\n",
      "model=bert_indonesian [f1] 0.8589, [precision] 0.9104, [recall] 0.8566\n",
      "model=distilbert_base [f1] 0.8592, [precision] 0.9154, [recall] 0.8521\n",
      "model=bert_base [f1] 0.8624, [precision] 0.9186, [recall] 0.8563\n",
      "<<<ensemble_ANY>>>: [f1] 0.8622, [precision] 0.8591, [recall] 0.9148\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8764, [precision] 0.925, [recall] 0.8777\n",
      "<<<ensemble_ALL>>>: [f1] 0.0689, [precision] 0.1837, [recall] 0.046\n",
      "=========================================================\n",
      "THRESHOLD: 18.5\n",
      "model=xlm_roberta_base [f1] 0.8555, [precision] 0.8772, [recall] 0.8837\n",
      "model=bert_indonesian [f1] 0.86, [precision] 0.8987, [recall] 0.8692\n",
      "model=distilbert_base [f1] 0.8632, [precision] 0.9086, [recall] 0.8644\n",
      "model=bert_base [f1] 0.8654, [precision] 0.9101, [recall] 0.8688\n",
      "<<<ensemble_ANY>>>: [f1] 0.8525, [precision] 0.8362, [recall] 0.9252\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8789, [precision] 0.9158, [recall] 0.8901\n",
      "<<<ensemble_ALL>>>: [f1] 0.0675, [precision] 0.1784, [recall] 0.0454\n",
      "=========================================================\n",
      "THRESHOLD: 19.0\n",
      "model=xlm_roberta_base [f1] 0.8441, [precision] 0.8497, [recall] 0.8952\n",
      "model=bert_indonesian [f1] 0.8583, [precision] 0.8833, [recall] 0.8821\n",
      "model=distilbert_base [f1] 0.8646, [precision] 0.8969, [recall] 0.8792\n",
      "model=bert_base [f1] 0.8654, [precision] 0.8976, [recall] 0.8814\n",
      "<<<ensemble_ANY>>>: [f1] 0.8329, [precision] 0.8017, [recall] 0.935\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8788, [precision] 0.9029, [recall] 0.903\n",
      "<<<ensemble_ALL>>>: [f1] 0.0649, [precision] 0.1699, [recall] 0.044\n",
      "=========================================================\n",
      "THRESHOLD: 19.5\n",
      "model=xlm_roberta_base [f1] 0.8196, [precision] 0.8073, [recall] 0.9066\n",
      "model=bert_indonesian [f1] 0.85, [precision] 0.86, [recall] 0.8941\n",
      "model=distilbert_base [f1] 0.8615, [precision] 0.8803, [recall] 0.8918\n",
      "model=bert_base [f1] 0.861, [precision] 0.8797, [recall] 0.8931\n",
      "<<<ensemble_ANY>>>: [f1] 0.7978, [precision] 0.7493, [recall] 0.9441\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8725, [precision] 0.883, [recall] 0.9141\n",
      "<<<ensemble_ALL>>>: [f1] 0.0665, [precision] 0.1704, [recall] 0.0454\n",
      "=========================================================\n",
      "THRESHOLD: 20.0\n",
      "model=xlm_roberta_base [f1] 0.7776, [precision] 0.7463, [recall] 0.9169\n",
      "model=bert_indonesian [f1] 0.8355, [precision] 0.8301, [recall] 0.9058\n",
      "model=distilbert_base [f1] 0.8512, [precision] 0.8551, [recall] 0.903\n",
      "model=bert_base [f1] 0.851, [precision] 0.8542, [recall] 0.9053\n",
      "<<<ensemble_ANY>>>: [f1] 0.7442, [precision] 0.6786, [recall] 0.953\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8603, [precision] 0.856, [recall] 0.9245\n",
      "<<<ensemble_ALL>>>: [f1] 0.0625, [precision] 0.1588, [recall] 0.043\n",
      "=========================================================\n",
      "THRESHOLD: 20.5\n",
      "model=xlm_roberta_base [f1] 0.7171, [precision] 0.6667, [recall] 0.928\n",
      "model=bert_indonesian [f1] 0.8093, [precision] 0.7859, [recall] 0.9185\n",
      "model=distilbert_base [f1] 0.8323, [precision] 0.8207, [recall] 0.9142\n",
      "model=bert_base [f1] 0.8335, [precision] 0.8201, [recall] 0.9177\n",
      "<<<ensemble_ANY>>>: [f1] 0.6697, [precision] 0.5891, [recall] 0.9611\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8386, [precision] 0.8161, [recall] 0.9356\n",
      "<<<ensemble_ALL>>>: [f1] 0.0563, [precision] 0.141, [recall] 0.0395\n",
      "=========================================================\n",
      "THRESHOLD: 21.0\n",
      "model=xlm_roberta_base [f1] 0.6364, [precision] 0.5706, [recall] 0.9377\n",
      "model=bert_indonesian [f1] 0.7661, [precision] 0.7239, [recall] 0.9305\n",
      "model=distilbert_base [f1] 0.8, [precision] 0.7706, [recall] 0.9252\n",
      "model=bert_base [f1] 0.804, [precision] 0.7729, [recall] 0.9288\n",
      "<<<ensemble_ANY>>>: [f1] 0.5689, [precision] 0.4778, [recall] 0.9677\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.8049, [precision] 0.7643, [recall] 0.9448\n",
      "<<<ensemble_ALL>>>: [f1] 0.0513, [precision] 0.1269, [recall] 0.0365\n",
      "=========================================================\n",
      "THRESHOLD: 21.5\n",
      "model=xlm_roberta_base [f1] 0.5389, [precision] 0.4632, [recall] 0.9486\n",
      "model=bert_indonesian [f1] 0.7031, [precision] 0.6434, [recall] 0.9402\n",
      "model=distilbert_base [f1] 0.7494, [precision] 0.7011, [recall] 0.9359\n",
      "model=bert_base [f1] 0.756, [precision] 0.7052, [recall] 0.9403\n",
      "<<<ensemble_ANY>>>: [f1] 0.454, [precision] 0.3612, [recall] 0.9744\n",
      "<<<ensemble_MAJOR>>>: [f1] 0.752, [precision] 0.6914, [recall] 0.9555\n",
      "<<<ensemble_ALL>>>: [f1] 0.0469, [precision] 0.1112, [recall] 0.0339\n"
     ]
    }
   ],
   "source": [
    "df_result = []\n",
    "for th in np.arange(15, 22, 0.5):\n",
    "    print(\"=========================================================\")\n",
    "    print(f\"THRESHOLD: {th}\")\n",
    "    for model_name in model_dict.keys():\n",
    "        f1score, precision, recall = get_cv(df, \n",
    "                                            model_dist_dict[model_name][\"distances\"],\n",
    "                                            th,\n",
    "                                            posting_id,\n",
    "                                            model_dist_dict[model_name][\"indices\"],\n",
    "                                            pred_name=model_name,\n",
    "                                            min_n=2)\n",
    "        print(f\"model={model_name} [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "\n",
    "    df[\"pred\"] = df.apply(combine_predictions_any, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ANY>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_major, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_MAJOR>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")\n",
    "    \n",
    "    df[\"pred\"] = df.apply(combine_predictions_all, axis=1)\n",
    "    f1score, precision, recall = calc_cv(df, col_name=\"pred\")\n",
    "    print(f\"<<<ensemble_ALL>>>: [f1] {round(f1score, 4)}, [precision] {round(precision, 4)}, [recall] {round(recall, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
